{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18ed88a",
   "metadata": {},
   "source": [
    "# Numerical Integration and Differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6490434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact, widgets\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy import integrate, optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6e48ad",
   "metadata": {},
   "source": [
    "## Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d332e51c",
   "metadata": {},
   "source": [
    "In elementary geometry you learned how to calculate the area and volume of simple shapes like circles, cubes, etc..\n",
    "\n",
    "The topic of this notebook (in contrast to the notebooks on solving ODE's and PDE's, where we will see methods to solve differential equations) is to determine the area under a curve and numerically differentiating curves.\n",
    "\n",
    "\n",
    "In fact, one of the motivations for the invention of integral calculus was the need to also calculate the area of more complex, irregular shapes.\n",
    "\n",
    "Methods for approximating the area of such irregular shapes were already known by Archimedes, whose approach was to tile the region with small squares (for which he know the area) and then count the total number of squares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4170614d",
   "metadata": {},
   "source": [
    "The principle behind this method is not too far from the currently used methods.\n",
    "\n",
    "Theoretically, for a function $f:\\mathbb{R}\\rightarrow\\mathbb{R}$ on an interval $[a,b]$, the definition of the integral \n",
    "\n",
    "$$I(f)=\\int_a^bf(x)\\, dx$$\n",
    "\n",
    "is based on the **Riemann sums** of the form\n",
    "\n",
    "$$R_n=\\sum^n_{i=1}(x_{i+1}-x_i)f(\\xi_i)$$\n",
    "\n",
    "where $a=x_1 <x_2<\\cdots<x_n<x_{n+1}=b$ and $\\xi_i\\in [x_i,x_{i+1}]$, $i=1,\\ldots,n$.\n",
    "\n",
    "Let $h_n=\\max\\{x_{i+1}-x_i:i=1,\\ldots,n-1\\}$. If for any choice of $x_i$ such that $h_n\\rightarrow 0$ and any choice of $\\xi_i$, we have $\\lim_{n\\rightarrow \\infty}R_n=R$, where $R$ is finite, then $f$ is said to be **Riemann integrable** on $[a,b]$, and the value of the integral is $R$.\n",
    "\n",
    "This method already suggests a method for approximating an integral: just use a finite Riemann sum with $n$ chosen large enough to achieve the desired accuracy. This idea works in principle, but in practice will be far from optimal in comparison to more efficient choices which carefully select $x_i$ and $\\xi_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b44f05-906a-4993-aef9-c33d2dbbbfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_concept():\n",
    "    def integrand(x):\n",
    "        return 1 / 15 * (6 * x - 3) * (x - 5) * (x - 7) + 6\n",
    "\n",
    "    plt.close(\"concept\")\n",
    "    fig, ax = plt.subplots(num=\"concept\")\n",
    "    ts = np.linspace(1, 9, 100)\n",
    "    ax.plot(ts, integrand(ts), color=\"Blue\")\n",
    "    ax.vlines(x=2, ymin=0, ymax=integrand(2), color=\"black\")\n",
    "    ax.vlines(x=8, ymin=0, ymax=integrand(8), color=\"black\")\n",
    "    rectangles = [\n",
    "        Rectangle((2, 0), 1, integrand(2.5), color=\"r\"),\n",
    "        Rectangle((3, 0), 1, integrand(3.5), color=\"r\"),\n",
    "        Rectangle((4, 0), 1, integrand(4.5), color=\"r\"),\n",
    "        Rectangle((5, 0), 1, integrand(5.5), color=\"r\"),\n",
    "        Rectangle((6, 0), 1, integrand(6.5), color=\"r\"),\n",
    "        Rectangle((7, 0), 1, integrand(7.5), color=\"r\"),\n",
    "    ]\n",
    "    for rectangle in rectangles:\n",
    "        ax.add_patch(rectangle)\n",
    "    ax.text(1.75, 1, \"a\")\n",
    "    ax.text(8.25, 1, \"b\")\n",
    "    ax.text(8, 30, \"r(x)\", color=\"Blue\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "\n",
    "\n",
    "plot_concept()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71730a6a-cfdc-4ee2-9e38-aa97f15c521e",
   "metadata": {},
   "source": [
    "## Existence, Uniqueness, Conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4b38c2",
   "metadata": {},
   "source": [
    "- For all practical purposes, a function is integrable if it is bounded (no singularities) with at most a finite number of points of discontinuity within the interval of integration. \n",
    "\n",
    "- Since all the Riemann sums defining the Riemann integral of a given function on a given interval must have the same limit, uniqueness of the Riemann integral is built into its definition.\n",
    "\n",
    "- The conditioning of an integration problem is a measure of the sensitivity to perturbations in the input data. Because integration is an averaging or smoothing process that tends to dampen the effect of small changes in the integrand, integration problems are typically well-behaved with a small condition number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a5773a",
   "metadata": {},
   "source": [
    "## Numerical Quadrature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53493a49-bbe6-405f-8abe-52409d34df60",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5b6421",
   "metadata": {},
   "source": [
    "In your calculus course you learned to evaluate a definite integral\n",
    "\n",
    "$$I(f)=\\int_b^af(x)\\,dx$$\n",
    "\n",
    "analytically by finding an **antiderivative** $F$ of the integrand function $f$, where \n",
    "\n",
    "$$I(f)=F(b)-F(a).$$\n",
    "\n",
    "Unfortunately, for some integrals such a closed form does not exist (e.g. $f(x)=\\exp(-x^2)$), or they are too complicated to evaluate.\n",
    "In these cases, you can use numerical methods to approximate the value of these integrals. \n",
    "\n",
    "The numerical approximation of definite integrals is called **numerical quadrature**. \n",
    "This name derives from the ancient methods for approximating areas of irregular shapes by tiling them by small squares, as mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceaccd8",
   "metadata": {},
   "source": [
    "To achieve this, we will build upon the definition of Riemann sums: the integral will be approximated by a weighted sum of integrand values at a finite number of sample points in the interval of integration.\n",
    "Specifically, the integral $I(f)$ is approximated by an $n$-point **quadrature rule**, which has the form\n",
    "\n",
    "$$Q_n(f)=\\sum_{i=1}^n w_i f(x_i),$$\n",
    "\n",
    "where $a\\leq x_1 < x_2 <\\ldots< x_{n}\\leq b$.\n",
    "\n",
    "The points $x_i$ at which the integrand $f$ is evaluated are called **nodes** or **abscissas**, and the multipliers $w_i$ are called **weights** or **coefficients**. A quadrature rule is said to be **open** if $a<x_1$ and $x_n<b$, and  **closed** if $a=x_1$ and $b=x_n$. \n",
    "\n",
    "In the next subsections, we will have a look at several methods to choose the nodes and weights with the goal to obtain the best accuracy at the lowest computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fec275",
   "metadata": {},
   "source": [
    "Quadrature rules can be derived using polynomial interpolation. \n",
    "Effectively, \n",
    "- The integrand function $f$ is evaluated at the points $x_i$, $i = 1,\\ldots, n$.\n",
    "- The polynomial of degree $n − 1$ that interpolates the function values at those points is determined.\n",
    "- The integral of the interpolant is then taken as an approximation to the integral of the original function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91abc8e7",
   "metadata": {},
   "source": [
    "To find the weights corresponding to a quadrature rule that integrates the first $n$ polynomial basis functions exactly, we can use the **method of undetermined coefficients**.\n",
    "\n",
    "If we use the monomial basis, e.g. this strategy results in the following **system of moment equations** with $n$ equations in $n$ unknowns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6326eb-c9b5-45ed-8a4d-65c0d1e56e71",
   "metadata": {},
   "source": [
    "#### General system of moment equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c3cf60",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "w_1\\cdot 1 +w_2\\cdot 1 +\\cdots+w_n\\cdot 1 &= \\int_a^b 1\\, dx = b-a \\\\\n",
    "w_1\\cdot x_1 +w_2\\cdot x_2 +\\cdots+w_n\\cdot x_n &= \\int_a^b x\\, dx = (b^2-a^2)/2 \\\\\n",
    "\\vdots \\\\\n",
    "w_1\\cdot x_1^{n-1} +w_2\\cdot x_2^{n-1} +\\cdots+w_n\\cdot x_n^{n-1} &= \\int_a^b x^{n-1}\\, dx = (b^n-a^n)/n\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "In matrix form this becomes:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1&1&\\cdots&1\\\\\n",
    "x_1&x_2&\\cdots&x_n\\\\\n",
    "\\vdots&\\vdots&\\ddots&\\vdots\\\\\n",
    "x_1^{n-1}&x_2^{n-1}&\\cdots&x_n^{n-1}\\end{bmatrix}\n",
    "\\begin{bmatrix}w_1\\\\w_2\\\\\\vdots\\\\w_n\\end{bmatrix}=\n",
    "\\begin{bmatrix}b-a\\\\(b^2-a^2)/2\\\\\\vdots\\\\(b^n-a^n)/n\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c191f35c",
   "metadata": {},
   "source": [
    "> **Example**\n",
    ">\n",
    "> As an example we use the method of undetermined coefficients to derive a three-point quadrature rule\n",
    ">\n",
    "> $$Q_3(f)=w_1f(x_1)+w_2f(x_2)+w_3f(x_3)$$\n",
    ">\n",
    "> for the interval $[a,b]$ using the monomial basis. \n",
    "> We take the two endpoints and the midpoint as the nodes:\n",
    "> - $x_1=a$\n",
    "> - $x_2=(a+b)/2$\n",
    "> - $x_3=b$\n",
    ">\n",
    "> This results in the following linear system:\n",
    ">\n",
    "> $$\\begin{bmatrix}\n",
    "1&1&1 \\\\\n",
    "a&(a+b)/2&b \\\\\n",
    "a^2&((a+b)/2)^2&b^2\\end{bmatrix}\n",
    "\\begin{bmatrix}w_1\\\\w_2\\\\w_3\\end{bmatrix}=\n",
    "\\begin{bmatrix}b-a\\\\(b^2-a^2)/2\\\\(b^3-a^3)/3\\end{bmatrix}\n",
    "$$\n",
    ">\n",
    "> Solving this system, we find the weights:\n",
    "> - $w_1 = (b-a)/6$\n",
    "> - $w_2 = 2(b-a)/3$\n",
    "> - $w_3 = (b-a)/6$\n",
    ">\n",
    "> The resulting quadrature rule is known as **Simpson's rule** and is an example of a Newton-Cotes quadrature rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c8ae9b-047d-46d3-976b-4cfbf89832ee",
   "metadata": {},
   "source": [
    "#### Accuracy and useful concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09f515a",
   "metadata": {},
   "source": [
    "By construction, an $n$-point interpolatory quadrature rule integrates each of the first $n$ monomial basis functions exactly, and hence by linearity it integrates any polynomial of degree at most $n-1$ exactly.\n",
    "A quadrature rule is said to be of **degree** $d$ if it is exact (i.e., the error is zero) for every polynomial of degree $d$ but is not exact for some polynomial of degree $d + 1$.\n",
    "An $n$-point interpolatory quadrature rule is of degree at least $n-1$.\n",
    "\n",
    "\n",
    "The significance of the degree is that it conveniently characterizes the **accuracy** of a given rule. \n",
    "If $Q_n$ is an interpolatory quadrature rule, and $p_{n−1}$ is the polynomial of degree at most $n-1$  interpolating a sufficiently smooth integrand $f$ at the nodes $x_1,\\cdots,x_n$, then we get the following rough error bound for the approximate integral:\n",
    "\n",
    "$$\\|I(f)-Q_n(f)\\|\\leq\\frac{1}{4}h^{n+1}\\|f^{(n)}\\|_\\infty$$ \n",
    "\n",
    "where $h = \\max\\{x_{i+1} - x_i : i = 1,\\ldots, n-1\\}$.\n",
    "\n",
    "the preceding general bound already indicates that we can obtain higher accuracy by taking $n$ larger, or $h$ smaller, or both.\n",
    "\n",
    "- When the number of sample points is increased, say from $n$ to $m$, an important factor affecting efficiency is whether the $n$ function values already computed can be reused in the new rule, so that only $m-n$ new function values need be computed.\n",
    "A sequence of quadrature rules is said to be **progressive** if the nodes of $Q_{n1}$ are a subset of those of $Q_{n2}$ for $n_2 > n_1$ .\n",
    "\n",
    "- Instead of (or in addition to) increasing the number of points (and hence the degree), the preceding bound also suggests that the error can be reduced by subdividing the interval of integration into smaller subintervals and applying the quadrature rule separately in each, since this will reduce $h$.\n",
    "This approach, which is equivalent to using piecewise polynomial interpolation on the original interval, leads to **composite (or compound) quadrature rules**, which we will consider below.\n",
    "For now, we will focus on **simple quadrature rules**, in which a single rule is applied over the entire given interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4988945-bdf8-4688-87d0-4fcb1e5d2b63",
   "metadata": {},
   "source": [
    "### Newton-Cotes  Quadrature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f19f1-1d57-48f3-aecf-28495ef963bb",
   "metadata": {},
   "source": [
    "#### Definition and common cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e30821",
   "metadata": {},
   "source": [
    "The simplest placement of nodes for an interpolatory quadrature rule is to choose equally spaced points in the interval $[a, b]$, which is the defining property of **Newton-Cotes quadrature**.\n",
    "An $n$-point **open Newton-Cotes rule** excludes the edges and has nodes:\n",
    "\n",
    "$$x_i = a + i (b − a)/(n + 1)\\quad,\\quad  i = 1,\\cdots, n.$$\n",
    "\n",
    "An $n$-point **closed Newton-Cotes rule** includes the edges and has nodes:\n",
    "\n",
    "$$x_i = a + (i − 1) (b − a)/(n − 1)\\quad,\\quad i = 1,\\cdots, n.$$\n",
    "\n",
    "The simplest and best known examples are:\n",
    "\n",
    "- **The midpoint rule**.\n",
    "  Interpolating the function value at the midpoint of the interval by  a polynomial of degree zero (i.e., a constant) gives the one-point   open Newton-Cotes rule known as **the midpoint rule**:\n",
    "\n",
    "    $$M(f)=(b-a)f\\left(\\frac{a+b}{2}\\right)$$\n",
    "\n",
    "- **The trapezoid rule**\n",
    "  Interpolating the function values at the two endpoints of the interval by a polynomial of degree one (i.e., a straight line) gives the two-point closed Newton-Cotes rule known as **the trapezoid rule**:\n",
    "\n",
    "    $$T(f)=\\frac{b-a}{2}(f(a)+f(b))$$\n",
    "\n",
    "- **Simpson's rule**\n",
    "  Interpolating the function values at the two endpoints and the midpoint by a polynomial of degree two (i.e., a quadratic) gives the three-point closed Newton-Cotes rule known as **Simpson’s rule**:\n",
    "\n",
    "    $$S(f)=\\frac{b-a}{6}\\left(f(a)+4 f\\left(\\frac{a+b}{2}\\right)+f(b)\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8295609c",
   "metadata": {},
   "source": [
    "> **Example**\n",
    "> \n",
    "> To illustrate the application of Newton-Cotes quadrature rules, we approximate the integral\n",
    ">\n",
    "> $$I(f)=\\int_0^1e^{-x^2}\\,dx$$\n",
    ">\n",
    "> using each of the three Newton-Cotes quadrature rules just given.\n",
    "> \n",
    "> $$\n",
    "\\begin{aligned}\n",
    "M(f) &= (1-0)\\exp(-0.25)\\approx 0.778801 \\\\\n",
    "T(f) &= \\frac{1}{2}(\\exp(0) + \\exp(−1))\\approx 0.683940 \\\\\n",
    "S(f) &= \\frac{1}{6}\\left(\\exp(0) + 4 \\exp(−0.25) + \\exp(−1)\\right)\\approx0.747180\n",
    "\\end{aligned}\n",
    "$$\n",
    ">\n",
    "> The correctly rounded result for this problem is 0.746824. \n",
    ">\n",
    "> It is somewhat surprising to see that: \n",
    "> - the magnitude of the error from the trapezoid rule (0.062884) is about twice that from the midpoint rule (0.031977), \n",
    "> - and that Simpson’s rule, with an error of only 0.000356, seems remarkably accurate considering the size of the interval over which it is applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabc4306-dc1e-4bb4-9f3a-fa14d6f90283",
   "metadata": {},
   "source": [
    "#### Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c6f7b",
   "metadata": {},
   "source": [
    "The errors of the three Newton-Cotes rules can be analyzed with a Taylor series expansion of the integrand $f$ about the midpoint $m = (a + b)/2$ of the interval $[a, b]$:\n",
    "\n",
    "$$f(x)=f(m)+f'(m)(x-m)+\\frac{f''(m)}{2}(x-m)^2+\\frac{f'''(m)}{6}(x-m)^3+\\frac{f^{(4)}(m)}{24}(x-m)^4+\\cdots$$\n",
    "\n",
    "Integrating this Taylor series from $a$ to $b$ leads to an exact expression for the integral, when all terms are included.\n",
    "Note that the odd-order terms drop out, yielding:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  I(f) &= f(m) (b-a)+ \\frac{f''(m)}{24}(b-a)^3+\\frac{f^{(4)}(m)}{1920}(b-a)^5+\\cdots \\\\\n",
    "  &=M(f)+E(f)+F(f)+\\cdots\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $M(f)$, $E(f)$ and $F(f)$ represent the first three terms in the exact expression for the integral.\n",
    "Below, we will write the three Newton-Cotes rules in terms of the Taylor series and compare the outcome to the exact answer.\n",
    "This will reveal the errors of those rules, broken down in different contributions of the form $c_p(b-a)^p$, where $p$ is always an odd power and $c_p$ is a linear coefficient.\n",
    "\n",
    "- **Midpoint rule**\n",
    "\n",
    "  The midpoint rule simply coincides with the first term of $I(f)$, namely $M(f)$, meaning that the leading-order term of the error is $E(f)$.\n",
    "  Hence, the error is proportional to the width of the interval cubed.\n",
    "\n",
    "- **Trapezoid rule**\n",
    "\n",
    "  To derive a comparable error expansion for the trapezoid quadrature rule, evaluate the Taylor series twice, once for $x = a$ and once for $x = b$.\n",
    "  Substitute these results into the rule $\\frac{f(b)+f(a)}{2}(b - a)$.\n",
    "  Then, observe once again that the odd-order terms drop out, and rewrite the leading terms as a function of $M(f)$, $E(f)$ and $F(f)$.\n",
    "  This will result in:\n",
    "\n",
    "    $$T(f) = M(f) + 3E(f) + 5F(f) + \\cdots$$\n",
    "\n",
    "    We may now compute the difference with the exact solution:\n",
    "\n",
    "    $$T(f) - I(f) = 2E(f) + 4F(f) + \\cdots$$\n",
    "\n",
    "    We may also compute other differences:\n",
    "\n",
    "    $$T(f) - M(f) = 3E(f) + 5F(f) + \\cdots$$\n",
    "\n",
    "    and hence the difference between the two quadrature rules provides an estimate for the dominant term in their error expansions\n",
    "\n",
    "    $$E(f)\\approx\\frac{T(f)-M(f)}{3}$$\n",
    "\n",
    "    provided that the length of the interval is sufficiently small that $(b-a)^5 \\ll (b-a)^3$, and the integrand $f$ is such that $f^{(4)}$ is well-behaved. \n",
    "\n",
    "    Under these assumptions, we may draw several conclusions from the preceding derivations\n",
    "\n",
    "  1. The midpoint rule is about twice as accurate as the trapezoid rule, despite being based on a polynomial interpolant of degree one less.\n",
    "\n",
    "  2. The difference between the midpoint rule and the trapezoid rule can be used to estimate the error in either of them.\n",
    "\n",
    "  3. Halving the length of the interval decreases the error in either rule by a factor of about $1/8$.\n",
    "\n",
    "\n",
    "- **Simpson's rule**\n",
    "\n",
    "  An appropriately weighted combination of the midpoint and trapezoid rules eliminates the leading term, $E(f)$, from the error expansion:\n",
    "\n",
    "    $$S(f) = \\frac{2}{3}M(f) + \\frac{1}{3}T(f) = M(f) + E(f) + \\frac{5}{3}T(f) + \\ldots$$\n",
    "\n",
    "    with error\n",
    "\n",
    "    $$S(f) - I(f)=\\frac{2}{3}F(f)+\\cdots$$\n",
    "\n",
    "    which provides an alternative derivation for Simpson’s rule as well as an expression for its dominant error term.\n",
    "\n",
    "In general, for any odd value of $n$, an $n$-point Newton-Cotes rule has degree one greater than that of the polynomial interpolant on which it is based due to cancellation of positive and negative errors.\n",
    "\n",
    "This implies that the midpoint rule integrates linear polynomials exactly, and hence its degree is one rather than zero. Similarly, the error for Simpson’s rule depends on the fourth and higher derivatives in the Taylor expansion, which vanish for cubic as well as quadratic polynomials, so that Simpson’s rule is of degree three rather than two (which explains the surprisingly high accuracy obtained in the previous example).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80605b6",
   "metadata": {},
   "source": [
    "> **Example**\n",
    ">\n",
    "> We illustrate these error estimates by computing the approximate value for the integral\n",
    ">\n",
    "> $$\\int_0^1 x^2\\,dx$$\n",
    ">\n",
    "> Using the midpoint rule, we obtain\n",
    ">\n",
    "> $$M(f)= (1-0)\\left(\\frac{1}{2}\\right)^2=\\frac{1}{4}$$\n",
    ">\n",
    "> and using the trapezoid rule we obtain\n",
    ">\n",
    "> $$T(f)=\\frac{1-0}{2}(0^2+1^2)=1/2$$\n",
    ">\n",
    "> Thus, we have the error estimate\n",
    ">\n",
    "> $$E(f)\\approx\\frac{T(f)-M(f)}{3}=\\frac{1/4}{3}=\\frac{1}{12}$$\n",
    ">\n",
    "> We conclude that the error in $M(f)$ is about $1/12$ and the error in $T(f)$ is about $-1/6$.\n",
    "> In addition, we can now compute the approximate value given by Simpson’s rule for this integral,\n",
    ">\n",
    "> $$S(f)=\\frac{2}{3}M(f)+\\frac{1}{3}T(f)=\\frac{2}{3}\\cdot\\frac{1}{4}+\\frac{1}{3}\\cdot\\frac{1}{2}=\\frac{1}{3}$$\n",
    ">\n",
    "> which is exact for this integral (as is to be expected since, by design, Simpson’s rule is exact for quadratic polynomials). \n",
    "> Thus, the error estimates for $M(f)$ and $T(f)$ are exact for this integrand (though this would not be true in general)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa46c55b-068f-4ae1-ad24-d24254d7349d",
   "metadata": {},
   "source": [
    "#### Closing remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e47bb37",
   "metadata": {},
   "source": [
    "Newton-Cotes quadrature rules are relatively easy to derive and to apply, but they have some serious drawbacks. \n",
    "The interpolation of a continuous function at equally spaced points by a high-degree polynomial may suffer from unwanted oscillation, and as the number of interpolation points grows, convergence to the underlying function is not guaranteed.\n",
    "\n",
    "it can be shown that every n-point Newton-Cotes rule with $n \\geq 11$ has at least one negative weight and that the sum of all weights tends to infinity as $n\\rightarrow \\infty$.\n",
    "\n",
    "This means that Newton-Cotes rules become arbitrarily ill-conditioned, and hence unstable, as the number of points grows.\n",
    "The presence of large positive and negative weights also means that the value of the integral is computed as a sum of large quantities of differing sign, and hence substantial cancellation is likely in finite-precision arithmetic.\n",
    "\n",
    "For these reasons, we cannot expect to attain arbitrarily high accuracy on a given interval by using a Newton-Cotes rule with a large number of points. \n",
    "In practice, therefore, Newton-Cotes rules are usually restricted to a modest number of points, and if higher accuracy is required, then the interval is subdivided and the rule is applied in each subinterval separately (as we'll see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c656178-5185-4b53-a5d3-09f067bd9c24",
   "metadata": {},
   "source": [
    "#### Example integrand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492c9b51-f7f5-4efc-a6de-2907d15f5993",
   "metadata": {},
   "source": [
    "Throughout this notebook, integration algorithms are often tested with the same test case:\n",
    "\n",
    "$$I = \\int_0^1 \\exp(-x^2)\\,dx$$\n",
    "\n",
    "The function and the full double precision answer are defined in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa722c3e-f5c0-4b2a-81e9-6fa533f8902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return np.exp(-(x**2))\n",
    "\n",
    "\n",
    "EXACT = 0.746824132812427"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4221450c-a2a8-49e0-9c7c-0c45a4f824ad",
   "metadata": {},
   "source": [
    "#### DIY `scipy` integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b29525",
   "metadata": {},
   "source": [
    "The [`integrate.newton_cotes`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.newton_cotes.html) function returns the weights and error coefficient for Newton-Cotes integration with $n$ equally spaced data points. \n",
    "\n",
    "It can therefore be used to compute the integral of a function, using as many points as you wish to evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a937345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_newton_cotes(rn):\n",
    "    a = 0\n",
    "    b = 1\n",
    "    x = np.linspace(a, b, rn + 1)\n",
    "    an, _B = integrate.newton_cotes(rn, 1)\n",
    "    dx = (b - a) / rn\n",
    "    quad = dx * np.sum(an * func(x))\n",
    "    error = abs(quad - EXACT)\n",
    "    return quad, error\n",
    "\n",
    "\n",
    "def demo_newton_cotes_weakness():\n",
    "    rns = np.arange(1, 45)\n",
    "    errors = []\n",
    "\n",
    "    print(f\"{'Order':<6} {'Quadrature Result':<18} {'Error'}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    for rn in rns:\n",
    "        quad, error = demo_newton_cotes(rn)\n",
    "        print(f\"{rn:<6} {quad:<18.9f} {error:.5e}\")\n",
    "        errors.append(error)\n",
    "\n",
    "    # Plotting the error as a function of quadrature order\n",
    "    plt.close(\"newton_cotes_weakness\")\n",
    "    fig, ax = plt.subplots(figsize=(7, 4), num=\"newton_cotes_weakness\")\n",
    "    ax.plot(rns, errors, marker=\"o\", linestyle=\"-\", color=\"blue\")\n",
    "    ax.set_xlabel(\"Order of the quadrature rule (n)\")\n",
    "    ax.set_ylabel(\"Error\")\n",
    "    ax.set_title(\"Error in Newton-Cotes Quadrature\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "demo_newton_cotes_weakness()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5773165-ef0b-44c5-929c-9d76d7cd33b8",
   "metadata": {},
   "source": [
    "This graph effectively shows that more data points does not always mean better results.\n",
    "The optimal number of data points is in this example about 15, because this produces the smallest error.\n",
    "When we look at the value that corresponds with 15 data points, this is also an accurate approximation of the exact value.\n",
    "10 to 20 data points also approximate these values well, but as soon as the number of data points exceeds 35, the error becomes very large, very quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026195de-7841-447a-886b-06891803d239",
   "metadata": {},
   "source": [
    "### Clenshaw-Curtis Quadrature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f16250",
   "metadata": {},
   "source": [
    "We saw in the *interpolation* notebook that the Chebyshev points have distinct advantages over equally spaced points for interpolating a continuous function by a polynomial. \n",
    "Similarly, when choosing the nodes in a quadrature rule based on the Chebysev points, we also improve upon the Newton-Cotes rules.\n",
    "\n",
    "With the Chebyshev points as nodes for a given $n$, the corresponding weights can again be calculated using the method of undetermined coefficients. \n",
    "It can be shown that the resulting weights are always positive for any $n$, and that the resulting approximate\n",
    "values converge to the exact integral as $n \\rightarrow \\infty$.\n",
    "Thus, quadrature rules based on the Chebyshev points are extremely attractive in that they are always stable and\n",
    "significantly more accurate than Newton-Cotes rules for the same number of nodes.\n",
    "\n",
    "Additionally, this type of quadrature rule can be implemented using techniques based on the fast Fourier transform. \n",
    "These efficient implementations of quadrature rules based on the Chebyshev points have become\n",
    "known as **Clenshaw-Curtis quadrature**.\n",
    "\n",
    "We have seen that Clenshaw-Curtis quadrature rules have many virtues: stability, accuracy, simplicity and progressiveness.\n",
    "Nevertheless, the degree of an $n$-point rule is only $n − 1$, which is well below the maximum possible. \n",
    "Next, we will see that quadrature rules of maximum degree can be derived by exploiting all of the available degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d8292c-0603-4ced-9121-fee151d493aa",
   "metadata": {},
   "source": [
    "### Gaussian Quadrature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbb84b4",
   "metadata": {},
   "source": [
    "In all the preceding quadrature rules we chose the $n$ nodes ourselves and then determined the $n$ corresponding weights to maximize the degree of the resulting quadrature rule. \n",
    "With only n parameters free to be chosen, the resulting degree is generally $n − 1$.\n",
    "\n",
    "If the locations of the nodes were also freely chosen, however, then there would be $2n$ free parameters, so that a degree of $2n − 1$ should be achievable. \n",
    "In Gaussian quadrature, both the nodes and the weights are optimally chosen to maximize the degree of the resulting quadrature rule.\n",
    "\n",
    "In general, for each $n$ there is a unique $n$-point Gaussian rule, and it is of degree $2n − 1$.\n",
    "Gaussian quadrature rules therefore have the highest possible accuracy for the number of nodes used, but they are significantly more difficult to derive than Newton-Cotes rules. \n",
    "\n",
    "The nodes and weights can still be determined by the method of undetermined coefficients, but the resulting system of equations is nonlinear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85292f9",
   "metadata": {},
   "source": [
    "> **Example**\n",
    ">\n",
    "> We will derive a two-point Gaussian quadrature rule on the interval $[−1, 1]$,\n",
    ">\n",
    "> $$I(f)=\\int_{-1}^1f(x)dx\\approx w_1f(x_1)+w_2f(x_2)=G_2(f)$$\n",
    "> \n",
    "> where we can still freely choose $w_1,w_2$ and $x_1$ and $x_2$\n",
    ">\n",
    "> The requirement that the first four monomials need to be integrated exactly gives rise to the following equations\n",
    ">\n",
    "> $$\n",
    "\\begin{aligned}\n",
    "w_1+w_2 &= \\int_{-1}^1 1\\,dx=2 \\\\\n",
    "w_1x_1+w_2x_2 &= \\int_{-1}^1 x\\,dx=0 \\\\\n",
    "w_1x_1^2+w_2x_2^2 &= \\int_{-1}^1 x^2\\,dx=2/3 \\\\\n",
    "w_1x_1^3+w_2x_2^3 &= \\int_{-1}^1 x^3\\,dx=0\n",
    "\\end{aligned}\n",
    "$$\n",
    ">\n",
    "> Let's solve this nonlinear system using `scipy`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490aeedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_2point_a_eqs(x):\n",
    "    \"\"\"The multidimensional function containing the 4 equations above.\n",
    "\n",
    "    - `x[0]` and `x[1]` represent $w_1$ and $w_2$.\n",
    "    - `x[2]` and `x[3]` represent $x_1$ and $x_2$.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        x[0] + x[1] - 2,\n",
    "        x[0] * x[2] + x[1] * x[3],\n",
    "        x[0] * x[2] ** 2.0 + x[1] * x[3] ** 2.0 - 2.0 / 3.0,\n",
    "        x[0] * x[2] ** 3.0 + x[1] * x[3] ** 3.0,\n",
    "    ]\n",
    "\n",
    "\n",
    "# Solve this system with initial guess [1, 1, 1, 1].\n",
    "optimize.root(gauss_2point_a_eqs, [1, 1, 1, 1]).x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e4659f",
   "metadata": {},
   "source": [
    "> As shown above, one solution for this system is given by\n",
    ">\n",
    "> - $x_1=-1/\\sqrt{3}\\approx-0.57735027$\n",
    "> - $x_2=1/\\sqrt{3}\\approx0.57735027$\n",
    "> - $w_1=1$\n",
    "> - $w_2=1$\n",
    ">\n",
    "> Thus the two-point Gaussian quadrature rule has the form\n",
    ">\n",
    "> $$G_2(f)=f(-1/\\sqrt{3})+f(1/\\sqrt{3})$$\n",
    ">\n",
    "> and by construction it has degree three.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047e7066-9888-41b2-a047-7365c34e2d2d",
   "metadata": {},
   "source": [
    "Another example on how Gaussion Quadrature works, but now for the interval $[2, 8]$ and plotted for the integrand $f(x) = \\frac{1}{15}(6x-3)(x-5)(x-7)+3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51931710-cfb8-4605-96d3-50a1dbcafd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_2point_b_eqs(x):\n",
    "    return [\n",
    "        x[2] + x[3] - 6,\n",
    "        x[2] * x[0] + x[3] * x[1] - 30,\n",
    "        x[2] * x[0] ** 2 + x[3] * x[1] ** 2 - 168,\n",
    "        x[2] * x[0] ** 3 + x[3] * x[1] ** 3 - 1020,\n",
    "    ]\n",
    "\n",
    "\n",
    "def example_gc28():\n",
    "    def integrand(x):\n",
    "        return 1 / 15 * (6 * x - 3) * (x - 5) * (x - 7) + 3\n",
    "\n",
    "    solution = optimize.root(gauss_2point_b_eqs, [2, 2, 1, 1]).x\n",
    "    print(solution)\n",
    "    ts = np.linspace(1, 9, 100)\n",
    "    plt.close(\"gc28\")\n",
    "    fix, ax = plt.subplots(num=\"gc28\")\n",
    "    ax.plot(ts, integrand(ts), color=\"Blue\")\n",
    "    ax.vlines(x=2, ymin=0, ymax=integrand(2), color=\"black\")\n",
    "    ax.vlines(x=8, ymin=0, ymax=integrand(8), color=\"black\")\n",
    "    ax.vlines(x=solution[0], ymin=0, ymax=integrand(solution[0]), color=\"black\")\n",
    "    ax.vlines(x=solution[1], ymin=0, ymax=integrand(solution[1]), color=\"black\")\n",
    "    ax.text(1.5, 0, \"a\")\n",
    "    ax.text(7.5, 0, \"b\")\n",
    "    ax.text(2.75, 0, \"$x_1$\")\n",
    "    ax.text(6.25, 0, \"$x_2$\")\n",
    "    ax.text(8.5, 29, \"r(x)\", color=\"Blue\")\n",
    "\n",
    "\n",
    "example_gc28()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f82f74-0358-4139-a661-ca6903d1175f",
   "metadata": {},
   "source": [
    "#### Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ea096b",
   "metadata": {},
   "source": [
    "- These examples are typical in that for any $n$ the Gaussian **nodes are symmetrically** placed about the midpoint of the interval; for odd values of $n$ the midpoint itself is always a node.\n",
    "\n",
    "- This example is also typical in that the **nodes are usually irrational numbers**, even if the endpoints a and b are rational. \n",
    "This feature makes Gaussian rules relatively inconvenient to calculate by hand, compared to simple Newton-Cotes rules.\n",
    "Usually, tabulated values are used for Gaussian quadrature.\n",
    "\n",
    "- Gaussian quadrature rules are also harder to apply than Newton-Cotes rules because the weights and nodes are derived for some specific interval and thus any other interval of integration must be transformed into\n",
    "the standard interval for which the nodes and weights have been tabulated.\n",
    "\n",
    "If we want to use a quadrature rule that is tabulated on the interval $[\\alpha,\\beta]$,\n",
    "\n",
    "$$\\int_\\alpha^\\beta f(x)dx\\approx\\sum_{i=1}^n w_if(x_i)$$\n",
    "\n",
    "to approximate an integral on the interval $[a, b]$,\n",
    "\n",
    "$$I(g)=\\int_a^b g(t)\\, dt$$\n",
    "\n",
    "then we must use a change of variable from $x$ in $[\\alpha, \\beta]$ to $t$ in $[a, b]$.\n",
    "Many such transformations are possible, but a simple linear transformation\n",
    "\n",
    "$$t=\\frac{(b-a)x+a\\beta-b\\alpha}{\\beta-\\alpha}$$\n",
    "\n",
    "has the advantage of preserving the degree of the quadrature rule.\n",
    "The integral is then given by \n",
    "\n",
    "$$I(g)\\approx \\frac{b-a}{\\beta-\\alpha}\\sum^n_{i=1}w_i g\\left(\\frac{(b-a)x_i+a\\beta-b\\alpha}{\\beta-\\alpha}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdca0162",
   "metadata": {},
   "source": [
    "> **Example**\n",
    ">\n",
    "> To illustrate a change of interval, we use the two-point Gaussian quadrature rule G_2 derived for the interval $[−1, 1]$ in the previous example to approximate the integral\n",
    ">\n",
    "> $$I(g)=\\int^1_0e^{-t^2}\\,dt$$\n",
    ">\n",
    "> Using the linear transformation of variable just shown, we have\n",
    ">\n",
    "> $$ t=\\frac{x+1}{2}$$\n",
    ">\n",
    "> so that the integral is approximated by $G_2(g)$=\n",
    ">\n",
    "> $$\\frac{1}{2}\\left[\\exp\\left(-\\left(\\frac{(-1/\\sqrt{3})+1}{2}\\right)^2\\right)+ \\exp\\left(-\\left(\\frac{(1/\\sqrt{3})+1}{2}\\right)^2\\right)\\right]\\approx0.746595$$\n",
    ">\n",
    "> which is slightly more accurate than the result given by Simpson's rule for this integral, despite using only two points instead of three."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144f4bea",
   "metadata": {},
   "source": [
    "This algorithm is implemented in [`integrate.fixed_quad`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.fixed_quad.html#scipy.integrate.fixed_quad) which \"Integrate func from a to b using Gaussian quadrature of order n.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67785e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_quadrature():\n",
    "    \"\"\"Illustrate `integrate.quadrature` with the integral int_0^1 exp(-x**2) dx.\"\"\"\n",
    "    y, _ = integrate.fixed_quad(func, 0, 1, n=2)\n",
    "    print(f\"integral = {y:.10f}\")\n",
    "\n",
    "\n",
    "demo_quadrature()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be9b5e-42f5-49b3-beb9-aa2077f32573",
   "metadata": {},
   "source": [
    "In the figure above you see an example of a lineair transformation of the variable. This is needed because if you work with variable t, the integral has boundaries 0 and 1, this is not tabulated for Gaussian quadrature. When you work with variable x, the boundaries are given by -1 and 1, these values are tabulated for Gaussian quadrature and hence are simple to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e7dd60",
   "metadata": {},
   "source": [
    "By design, Gaussian quadrature rules have maximal degree, and hence optimal accuracy, for the number of points used. \n",
    "Moreover, it can be shown that the resulting weights are always positive for any $n$, so that Gaussian quadrature rules are always stable and the resulting approximate values converge to the exact integral as $n \\rightarrow \\infty$.\n",
    "\n",
    "\n",
    "Unfortunately, Gaussian quadrature rules also have a serious drawback:\n",
    "\n",
    "> for $m \\neq n$, $G_m$ and $G_n$ have no nodes in common (except for the midpoint when $m$ and $n$ are both odd).\n",
    "> Thus, Gaussian rules are **not progressive**, which means that when the number of nodes is increased, say from $n$ to $m$, $m$ new evaluations of the integrand are required rather than $m − n$. \n",
    "\n",
    "Avoiding this additional work is the motivation for **Kronrod quadrature rules**.\n",
    "Such rules come in pairs: an $n$-point Gaussian rule $G_n$ and a $(2n+1)$-point Kronrod rule $K_{2n+1}$ whose nodes are optimally chosen subject to the constraint that all of the nodes of $G_n$ are reused in $K_{2n+1}$.\n",
    "Thus, $n$ of the nodes used in $K_{2n+1}$ are prespecified, leaving the remaining $n + 1$ nodes, as well as all $2n + 1$ of the weights (including those corresponding to the nodes of $G_n$ ), free to be chosen to maximize the degree of the resulting rule.\n",
    "The rule $K_{2n+1}$ is therefore of degree $3n + 1$, whereas a true $(2n + 1)$-point Gaussian rule would be of degree $4n + 1$.\n",
    "Thus, there is a tradeoff between accuracy and efficiency.\n",
    "\n",
    "One of the main reasons for using two quadrature rules with different numbers of points is to obtain an error estimate for the approximate value of the integral based on the difference between the values given by the two rules.\n",
    "In using a Gauss-Kronrod pair, the value of $K_{2n+1}$ is taken as the approximation to the integral, and a realistic but conservative estimate for the error, based partly on theory and partly on experience, is given by\n",
    "\n",
    "$$(200\\|G_n-K_{2n+1}\\|)^{1.5}$$\n",
    "\n",
    "Because they efficiently provide both high accuracy and a reliable error estimate, Gauss-Kronrod rules are among the most effective quadrature methods available, and they form the basis for many of the quadrature routines in major software libraries. \n",
    "The pair of rules ($G_7$ , $K_{15}$ ), in particular, has become a commonly used standard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dcd35d-6364-4117-8107-0521954c4b79",
   "metadata": {},
   "source": [
    "### Composite Quadrature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04b6597",
   "metadata": {},
   "source": [
    "Thus far we have considered simple quadrature rules obtained by interpolating the integrand function by a single polynomial over the entire interval of integration. \n",
    "\n",
    "The accuracy of such a rule can be increased, and the error estimated, by increasing the number of interpolation points, and hence the corresponding degree of the polynomial interpolant. \n",
    "\n",
    "An alternative is to subdivide the original interval into two or more subintervals and apply a simple quadrature rule in each subinterval.\n",
    "Summing these partial results then yields an approximation to the overall integral.\n",
    "\n",
    "Such an approach is equivalent to using piecewise polynomial interpolation on the original interval and then integrating the piecewise interpolant to approximate the integral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5720adcf",
   "metadata": {},
   "source": [
    "A **composite**, or **compound**, quadrature rule on a given interval $[a, b]$ results from subdividing the interval into $k$ subintervals, typically of uniform length $h = (b − a)/k$, applying an $n$-point simple quadrature rule $Q_n$ in each subinterval, and then taking the sum of these results as the approximate value of the integral.\n",
    "\n",
    "If the rule $Q_n$ is open, then evaluating the composite rule will require $kn$ evaluations of the integrand function. \n",
    "If $Q_n$ is closed, on the other hand, then some of the points are repeated, so that only $k(n − 1) + 1$ evaluations of the integrand are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b2ed05",
   "metadata": {},
   "source": [
    "> **Example**\n",
    ">\n",
    "> If the interval $[a, b]$ is subdivided into $k$ subintervals of length $h = (b − a)/k$ and $x_j = a + jh$, $j = 0, \\ldots, k$, then the **composite midpoint rule** is given by\n",
    ">\n",
    "> $$M_k(f)= \\sum^k_{j=1} (x_j-x_{j-1})f\\left(\\frac{x_{j-1}+x_j}{2}\\right)=h\\sum^k_{j=1}f\\left(\\frac{x_{j-1}+x_j}{2}\\right)$$\n",
    ">\n",
    "> and the **composite trapezoid rule** is given by\n",
    ">\n",
    "> $$T_k(f)=\\sum^k_{j=1} \\frac{(x_j-x_{j-1})}{2} \\left(f(x_{j-1})+f(x_j)\\right)=h\\left(\\frac{1}{2}f(a)+f(x_1)+\\cdots+f(x_{k-1})+\\frac{1}{2}f(b)\\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9367bb3",
   "metadata": {},
   "source": [
    "- In principle, by taking $k$ sufficiently large it is possible to achieve arbitrarily high accuracy (up to the limit of the arithmetic precision) using a composite rule, even with an underlying rule $Q_n$ of low degree, although this may not be the most efficient way to attain a given level of accuracy.\n",
    "\n",
    "- Composite quadrature rules also offer a particularly simple means of estimating the error by using different levels of subdivision, which can easily be made progressive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2615b2b6-736d-4009-a3f4-dad88a8ef365",
   "metadata": {},
   "source": [
    "#### Composite midpoint rule demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c50fd96-ee34-4228-8f29-d9a67aedd630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_adaptive_general(num):\n",
    "    fig, ax = plt.subplots(num=num, clear=True)\n",
    "    a, b = 0, 1\n",
    "\n",
    "    # Generate x values for plotting the function\n",
    "    x_vals = np.linspace(a, b, 1000)\n",
    "    y_vals = func(x_vals)\n",
    "\n",
    "    # Plot the function for the midpoint rule\n",
    "    ax.plot(x_vals, y_vals, label=r\"$e^{-x^2}$\", color=\"green\")\n",
    "\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"f(x)\")\n",
    "    ax.axhline(0, color=\"black\", linewidth=0.5, linestyle=\"--\")\n",
    "\n",
    "    return ax, a, b\n",
    "\n",
    "\n",
    "def plot_midpoint_rule(n_subintervals_midpoint):\n",
    "    ax, a, b = plot_adaptive_general(\"midpoint_rule\")\n",
    "\n",
    "    # Calculate midpoints and function values for the midpoint rule.\n",
    "    midpoints_midpoint = np.linspace(\n",
    "        a + (b - a) / (2 * n_subintervals_midpoint),\n",
    "        b - (b - a) / (2 * n_subintervals_midpoint),\n",
    "        n_subintervals_midpoint,\n",
    "    )\n",
    "    midpoint_values = func(midpoints_midpoint)\n",
    "\n",
    "    # Highlight the midpoints and corresponding function values\n",
    "    # for the midpoint rule.\n",
    "    ax.scatter(\n",
    "        midpoints_midpoint,\n",
    "        midpoint_values,\n",
    "        color=\"red\",\n",
    "        label=f\"Midpoints (Intervals: {n_subintervals_midpoint})\",\n",
    "    )\n",
    "\n",
    "    # Draw rectangles representing the midpoint rule\n",
    "    # for the selected number of subintervals.\n",
    "    for j in range(n_subintervals_midpoint):\n",
    "        rect = plt.Rectangle(\n",
    "            (a + j * (b - a) / n_subintervals_midpoint, 0),\n",
    "            (b - a) / n_subintervals_midpoint,\n",
    "            midpoint_values[j],\n",
    "            alpha=0.3,\n",
    "            color=\"blue\",\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    # Calculate the exact integral\n",
    "    # and the numerical approximation using quad function.\n",
    "    numerical_integral = np.sum(midpoint_values) * (b - a) / n_subintervals_midpoint\n",
    "\n",
    "    # Calculate the error between the exact integral and the numerical approximation.\n",
    "    error = numerical_integral - EXACT\n",
    "    # Update the title with the error information.\n",
    "    ax.set_title(f\"Error: {error:.6f}, Intervals: {n_subintervals_midpoint}\")\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "# Use the interact function to update the plot based on the slider value.\n",
    "plt.close(\"midpoint_rule\")\n",
    "interact(\n",
    "    plot_midpoint_rule,\n",
    "    n_subintervals_midpoint=widgets.IntSlider(\n",
    "        value=2, min=1, max=20, step=1, description=\"Intervals\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3911cb-ea8d-479e-975c-09d226be4a3b",
   "metadata": {},
   "source": [
    "#### Composite trapezoid illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a8b664-b0fb-4d93-9d53-8f90ac96c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trapezoid_rule(n_subintervals_trapezoid):\n",
    "    ax, a, b = plot_adaptive_general(\"trapezoid_rule\")\n",
    "\n",
    "    # Calculate points for the trapezoidal rule.\n",
    "    x_points = np.linspace(a, b, n_subintervals_trapezoid + 1)\n",
    "    y_points = func(x_points)\n",
    "\n",
    "    # Highlight the endpoints and corresponding function values\n",
    "    # for the trapezoidal rule.\n",
    "    ax.scatter(\n",
    "        x_points,\n",
    "        y_points,\n",
    "        color=\"red\",\n",
    "        label=f\"Endpoints (Intervals: {n_subintervals_trapezoid + 1})\",\n",
    "    )\n",
    "\n",
    "    # Draw trapezoids representing the trapezoidal rule\n",
    "    # for the selected number of subintervals.\n",
    "    for j in range(n_subintervals_trapezoid):\n",
    "        x_left = x_points[j]\n",
    "        x_right = x_points[j + 1]\n",
    "        y_left = y_points[j]\n",
    "        y_right = y_points[j + 1]\n",
    "\n",
    "        # Draw trapezoid\n",
    "        ax.plot(\n",
    "            [x_left, x_right, x_right, x_left, x_left],\n",
    "            [0, 0, y_right, y_left, 0],\n",
    "            color=\"blue\",\n",
    "            alpha=0.3,\n",
    "        )\n",
    "        ax.fill_between(\n",
    "            [x_left, x_right], [y_left, y_right], color=\"blue\", alpha=0.3\n",
    "        )\n",
    "\n",
    "    # Calculate the exact integral and the numerical approximation\n",
    "    # using quad function.\n",
    "    numerical_integral = np.trapezoid(y_points, x_points)\n",
    "\n",
    "    # Calculate the error between the exact integral and the numerical approximation\n",
    "    error = numerical_integral - EXACT\n",
    "\n",
    "    # Update the title with the error information\n",
    "    ax.set_title(f\"Error: {error:.6f}, Intervals: {n_subintervals_trapezoid + 1}\")\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "# Use the interact function to update the plot based on the slider value\n",
    "plt.close(\"trapezoid_rule\")\n",
    "interact(\n",
    "    plot_trapezoid_rule,\n",
    "    n_subintervals_trapezoid=widgets.IntSlider(\n",
    "        value=2, min=1, max=20, step=1, description=\"Intervals\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ff8ea7",
   "metadata": {},
   "source": [
    "A composite quadrature rule with an error estimate suggests a simple automatic quadrature procedure: continue subdividing all the subintervals until the estimated overall error meets the desired accuracy tolerance. \n",
    "\n",
    "However, maintaining uniform subdivisions is grossly inefficient for many integrands, however, as large numbers of function evaluations may be expended in regions where the integrand function is well behaved and the accuracy tolerance is easily met. \n",
    "A more intelligent approach is **adaptive quadrature**, in which the interval of integration is selectively  refined to reflect the behavior of any particular integrand function.\n",
    "\n",
    "A typical adaptive quadrature strategy works as follows:\n",
    "1. First we need a pair of quadrature rules, say $Q_{n1}$ and $Q_{n2}$, whose difference provides an error estimate. \n",
    "A few examples are\n",
    "\n",
    "- The trapezoid and midpoint rules, whose difference overestimates the error in the more accurate rule by a factor of three (see above).\n",
    "- Greater efficiency is usually obtained with rules of higher degree, however, such as the Gauss-Kronrod pair ($G_7$ ,$K_{15}$ ). \n",
    "- Another alternative is to use a single rule at two different levels of subdivision; Simpson’s rule is a popular choice in this approach.\n",
    "\n",
    "In any case, to minimize the number of function evaluations required, the pair of rules should be progressive.\n",
    "\n",
    "The adaptive procedure is now conceptually simple: \n",
    "\n",
    "2. apply both rules $Q_{n1}$ and $Q_{n2}$ on the initial interval of integration $[a, b]$. \n",
    "3. If the resulting approximate values for the integral differ by more than the desired tolerance, divide the interval into two or more subintervals and repeat the procedure on each subinterval. \n",
    "4. If the tolerance is met on a given subinterval, then no further subdivision of that subinterval will be required. \n",
    "5. If the tolerance is not met on a given subinterval, then the subdivision process is repeated again, and so on until the tolerance is met on all subintervals.\n",
    "\n",
    "Such a strategy leads to a nonuniform sampling of the integrand function that places many sample points in regions where the function is difficult to integrate and relatively few points where the function is easily integrated.\n",
    "\n",
    "This conceptually simple explanation hides several practical implementation issues, $[$e.g. How should the stopping criterion be implemented? For example, should the error tolerance be relative (usually preferable), or absolute (in case the value of the integral is near zero), or a combination of the two?$]$, which we will not concern ourselves with here.\n",
    "\n",
    "The following code gives an example of an adaptive quadrature rule using the midpoint and trapezoid rules.\n",
    "This structrure is based on section 8.3.6, p.355 of Micheal Heath's book 'Scientific computing - an introductory survey (revised second edition)'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d395c30f-9fd0-4fb2-9e95-67821b43f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptquad(func, a, b, tol=10**-6):\n",
    "    \"\"\"\n",
    "    Calculate definite integrals based on adaptive quadrature.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        The function to be integrated from a to b.\n",
    "    a, b : float\n",
    "        The integration limits.\n",
    "    tol : float, optional\n",
    "        Desired error tolerance.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    I2 : float\n",
    "        Calculated value of the integral\n",
    "    \"\"\"\n",
    "    I1 = (b - a) * func(a + (b - a) / 2)  # midpoint rule\n",
    "    I2 = (b - a) * (func(a) + func(b)) / 2  # trapezoid rule\n",
    "    m = a + (b - a) / 2\n",
    "    if m <= a or m >= b:  # stopping criterion\n",
    "        print(\"Warning: Tolerance may not be met.\")\n",
    "        return I2\n",
    "    estimated_err = abs(I1 - I2) / 3\n",
    "    if estimated_err < tol:\n",
    "        return I2\n",
    "    else:\n",
    "        # call adaptquad recursively for each subinterval\n",
    "        return adaptquad(func, a, m, tol / 2) + adaptquad(func, m, b, tol / 2)\n",
    "\n",
    "\n",
    "def demo_adaptquad():\n",
    "    a = 0\n",
    "    b = np.pi\n",
    "    result = adaptquad(np.sin, a, b)\n",
    "    error = np.abs(2 - result)  # comparison with the analytical solution\n",
    "    print(f\"Adaptive quadrature = {result}\")\n",
    "    print(f\"Error on adaptive quadrature = {error}\")\n",
    "\n",
    "\n",
    "demo_adaptquad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2510a547-5369-4ff9-93ef-bcc02ffab443",
   "metadata": {},
   "source": [
    "## Other integration problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3918c6-0523-496c-b216-7f4398cce84d",
   "metadata": {},
   "source": [
    "### Tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f260d",
   "metadata": {},
   "source": [
    "Thus far we have assumed that the integrand function can be evaluated at any desired point within the interval of  integration.\n",
    "This assumption may not be valid if the integrand is defined only by a table of its values at selected discrete points, as is typical of empirical measurements, for example.\n",
    "\n",
    "A reasonable approach to integrating such tabular data is by piecewise interpolation. \n",
    "For example, integrating the piecewise linear interpolant to tabular data gives a composite trapezoid rule.\n",
    "\n",
    "An excellent method for integrating tabular data is provided by Hermite cubic or cubic spline interpolation.\n",
    "In effect, the overall integral is computed by integrating analytically each of the cubic pieces that make up the interpolant.\n",
    "\n",
    "As an example of how to perform such integrations with `scipy`, we'll integrate tabular data containing 10 equally spaced function evaluations between 0 and 1 of the function\n",
    "\n",
    "$$f(x)=e^{-x^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c6f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_tabular(n):\n",
    "    \"\"\"Demo of integrate.simpson to integrate tabular data.\n",
    "\n",
    "    Note that, as the number of samples, n, increases,\n",
    "    the integration tends towards the theoretical result of\n",
    "    int_0^1 exp(-x^2) = 0.7468241328901555.\n",
    "\n",
    "    Also note that the accuracy is much better for even numbers\n",
    "    of points (odd number of intervals) because Simpsons rule\n",
    "    requires this, and falls back on the less accurate trapezoidal\n",
    "    rule in case of an even number of data points.\n",
    "    \"\"\"\n",
    "    x = np.linspace(0.0, 1.0, num=n)\n",
    "    y = func(x)\n",
    "    return integrate.simpson(y, x)\n",
    "\n",
    "\n",
    "for i in np.arange(2, 12):\n",
    "    result = demo_tabular(i)\n",
    "    err = np.abs(result - EXACT)\n",
    "    print(f\"{i:2d}  {result:18.15f}  {err:9.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0be449-6142-42f6-82f5-b7c8f740b173",
   "metadata": {},
   "source": [
    "### Improper integrals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ca62a7-709e-4995-b8fd-a925b92939f8",
   "metadata": {},
   "source": [
    "Boundedness of both the integrand function and the interval of integration are inherent in the definition of the Riemann integral. \n",
    "If either the integrand (containing a singularity) or the interval (at least one of the limits is $\\infty$) is unbounded, then it may still be possible to define an improper integral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f3f111-984c-4904-b4ae-7ddd00b33fdf",
   "metadata": {},
   "source": [
    "#### Integrating an integral with unbounded interval of integration:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bf9c9c-fde3-4eb8-8593-f71026acfb8d",
   "metadata": {},
   "source": [
    "- Replace any infinite limit of integration by a finite value. \n",
    "Such a finite limit should be chosen carefully so that the omitted tail is negligible or its contribution to the integral can be estimated. But the remaining finite interval should not be so wide that an adaptive quadrature routine will be fooled into sampling the integrand badly.\n",
    "\n",
    "- Transform the variable of integration so that the new interval is finite. Typical transformations include $x = − \\log t$ or $x = t/(1 − t)$.\n",
    "Care must be taken not to introduce singularities or other difficulties by such a transformation.\n",
    "\n",
    "- Use a quadrature rule, such as Gauss–Laguerre or Gauss–Hermite, that is designed for an unbounded interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e60d205-81ca-4cee-81d9-da5131877ff9",
   "metadata": {},
   "source": [
    "#### Integrating an integral with singularities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e178e32",
   "metadata": {},
   "source": [
    "For an integrand having an integrable singularity within the interval of integration, one may be tempted simply to try an adaptive quadrature routine and hope that it will work, but such an approach is unlikely to prove satisfactory. \n",
    "Outright failure will result if the integrand happens to be evaluated at the singularity, which will likely occur if the singularity lies at one of the endpoints, as singularities often do. \n",
    "Even if the routine is lucky enough to avoid evaluating the integrand at the singularity, an adaptive quadrature routine will generally be extremely inefficient for an integrand having a singularity because polynomials, which never have vertical asymptotes, cannot efficiently approximate functions that do (recall that our error bounds depend on higher derivatives of the integrand, which will inevitably be large near a singularity).\n",
    "\n",
    "A better approach for dealing with a singularity in the integrand is to remove the singularity either by transforming the variable of integration or by dividing out or subtracting off an analytically integrable function having the same singularity.\n",
    "\n",
    "There is often some art involved in finding such transformations, and not all singularities are removable in this manner.\n",
    "If there is more than one singularity, then the transformations required to remove them may conflict, in which case a remedy is to break the interval of integration into subintervals, each of which contains at most one singularity, typically at one endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6e34c2-ccbc-4194-8c4a-9f9a8fda61ca",
   "metadata": {},
   "source": [
    "### Double integrals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955ce504",
   "metadata": {},
   "source": [
    "Thus far we have considered only one-dimensional integrals, where we wish to determine the area under a curve over an interval. \n",
    "In evaluating a two-dimensional, or double integral, we wish to compute the volume under a surface over a planar\n",
    "region.\n",
    "\n",
    "For a rectangular region $[a, b] \\times [c, d]$, a double integral has the form\n",
    "\n",
    "$$\\int_a^b\\int_c^df(x,y)\\,dx\\,dy$$\n",
    "\n",
    "The practical way of approximating such integrals is shown using the `scipy` example below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69710ba8",
   "metadata": {},
   "source": [
    "> **Example**\n",
    ">\n",
    "> Consider the exponential integral (with an unbounded integration interval):\n",
    ">\n",
    "> $$E_n(x)=\\int^\\infty_1\\frac{e^{-xt}}{t^n}\\,dt$$\n",
    ">\n",
    "> This can be calculated using `scipy.quad`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e73264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expt_integrand(t, x, n=3):\n",
    "    return np.exp(-x * t) / t**n\n",
    "\n",
    "\n",
    "def expt_int1(x, n=3):\n",
    "    return integrate.quad(expt_integrand, 1, np.inf, args=(x, n))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25db01d9",
   "metadata": {},
   "source": [
    "> The function which is integrated itself can also use the quad argument (though the error bound may underestimate the error due to possible numerical error in the integrand from the use of quad). \n",
    ">\n",
    "> The integral in this case is\n",
    ">\n",
    "> $$I_n=\\int^\\infty_0 \\int^\\infty_1\\frac{e^{-xt}}{t^n}\\,dt\\,dx=\\frac{1}{n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae5761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "integrate.quad(expt_int1, 0, np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b590b69",
   "metadata": {},
   "source": [
    "The mechanics for double and triple integration have been wrapped up into the functions `dblquad` and `tplquad`.\n",
    "These functions take the function to integrate and four, or six arguments, respectively. \n",
    "The limits of all inner integrals can be defined as functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac21208",
   "metadata": {},
   "outputs": [],
   "source": [
    "integrate.dblquad(expt_integrand, 0, np.inf, 1, np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df703b6b",
   "metadata": {},
   "source": [
    "> Here is an example for a triple integral:\n",
    ">\n",
    "> $$I=\\int^1_0 \\int_0^1 \\int_0^1 \\exp(x)\\,yz\\, dx\\, dy\\, dz$$\n",
    ">\n",
    "> The analytical solution is\n",
    ">\n",
    "> $$\\frac{e-1}{4}=0.4295704571$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751055c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "integrate.tplquad(lambda x, y, z: np.exp(x) * y * z, 0, 1, 0, 1, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b4d022-488c-472d-ab8c-8aba77cff66e",
   "metadata": {},
   "source": [
    "### Multiple integrals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cb150d",
   "metadata": {},
   "source": [
    "To evaluate a multiple integral in dimensions higher than two, the method above for double integrals still work in principle (and is used in `nquad`), but their cost grows rapidly with the number of dimensions.\n",
    "\n",
    "The only generally viable approach for computing integrals in higher dimensions is the **Monte Carlo method**.\n",
    "The function is sampled at $n$ points distributed randomly in the domain of integration, and then the mean of\n",
    "these function values is multiplied by the area (or volume, etc.) of the domain to obtain an estimate for the integral. \n",
    "The error in this estimate goes to zero as $1/\\sqrt{n}$.\n",
    "\n",
    "The Monte Carlo method is not competitive for integrals in one or two dimensions, but the beauty of the method is that its convergence rate is independent of the number of dimensions. \n",
    "Thus, for example, one million points in six dimensions amounts to only ten points per dimension, which is much better than any type of conventional quadrature rule would require for the same level of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7876bf",
   "metadata": {},
   "source": [
    "> Let us use the following integral as an example:\n",
    ">\n",
    "> $$\\int_0^1 \\int_0^1 \\dots \\int_0^1 x_1+x_2+...+x_N\\, dx_1\\, dx_2\\,\\ldots\\,dx_N$$\n",
    ">\n",
    "> In one dimension this becomes:\n",
    ">\n",
    "> $$\\int_0^1 x_1\\,dx_1$$\n",
    ">\n",
    "> In two dimensions:\n",
    ">\n",
    "> $$\\int_0^1 \\int_0^1 x_1+x_2\\,dx_1\\, dx_2$$\n",
    ">\n",
    "> And so on.\n",
    "> We'll look at the computational time needed to integrate this integral for the first 5 dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27241f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time(n):\n",
    "    name = str(f\"integrate.nquad((lambda *x_args: sum(x_args)), [(0, 1)]*{n})\")\n",
    "    return timeit.timeit(stmt=name, setup=\"from scipy import integrate\", number=1)\n",
    "\n",
    "\n",
    "def demo_multidim(n):\n",
    "    x = np.arange(1, n + 1)\n",
    "    y = np.zeros(n)\n",
    "\n",
    "    for i in np.arange(1, n + 1):\n",
    "        y[i - 1] = measure_time(i)\n",
    "\n",
    "    plt.close(\"multidim\")\n",
    "    fig, ax = plt.subplots(num=\"multidim\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.plot(x, y, \"o\")\n",
    "    ax.set_xlabel(\"number of dimensions\")\n",
    "    ax.set_ylabel(\"time (s)\")\n",
    "    ax.set_xticks(np.arange(1, n + 1))\n",
    "\n",
    "\n",
    "demo_multidim(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250d2907-6bdb-42a4-bc8c-29e7042d3f9b",
   "metadata": {},
   "source": [
    "The plot shows that the computational cost grows exponentially and becomes very high when the dimension is >=5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c0a23-4614-46df-8f7a-3df09579904f",
   "metadata": {},
   "source": [
    "## Numerical Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f57af5",
   "metadata": {},
   "source": [
    "Let's touch upon differentiation now.\n",
    "In contrast to integration, differentiation is an inherently sensitive problem, as small perturbations in the data can cause large changes in the result.\n",
    "\n",
    "Generally, when approximating the derivative of a function whose values are known only at a discrete set of points, a good approach is to fit some smooth function to the given discrete data and then differentiate the approximating function to approximate the derivatives of the original function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4a2b0e-6b24-456c-9bf3-8de558759fb8",
   "metadata": {},
   "source": [
    "### Finite Difference Approximations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2ff069-8eaa-4507-9a3a-133f4480950a",
   "metadata": {},
   "source": [
    "Although finite difference formulas are generally inappropriate for discrete or noisy data, they are very useful for approximating derivatives of a smooth function that is known analytically, or can be evaluated accurately for any given argument, or is defined implicitly by a differential equation.\n",
    "\n",
    "The following equations will be useful for the next notebooks, where we'll deal with the numerical solution of differential equations.\n",
    "\n",
    "We want to approximate the first and second derivatives of a smooth function $f:\\mathbb{R}\\rightarrow\\mathbb{R}$ at a point $x$.\n",
    "\n",
    "For a given step size $h$, we consider the Taylor series expansions\n",
    "\n",
    "$$f(x+h)=f(x)+f'(x)h+\\frac{f''(x)}{2}h^2+\\frac{f'''(x)}{6}h^3+\\cdots$$\n",
    "\n",
    "and\n",
    "\n",
    "$$f(x-h)=f(x)-f'(x)h+\\frac{f''(x)}{2}h^2-\\frac{f'''(x)}{6}h^3+\\cdots$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0628e809-b841-4bdd-b9b4-0a1756d8b0b1",
   "metadata": {},
   "source": [
    "#### Approximations for the first derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc0755c-eb84-405c-ab71-83753d341ef6",
   "metadata": {},
   "source": [
    "- Solving the first series for $f'(x)$, we obtain the **forward difference formula**\n",
    "\n",
    "    $$f'(x)=\\frac{f(x+h)-f(x)}{h}-\\frac{f''(x)}{2}h+\\cdots\\approx\\frac{f(x+h)-f(x)}{h}$$\n",
    "\n",
    "    This approximation is first-order accurate since the dominant remainder of the series is $\\mathcal{O}(h)$.\n",
    "\n",
    "- Similarly, we obtain the **backward difference formula** from the second series:\n",
    "\n",
    "    $$f'(x)=\\frac{f(x)-f(x-h)}{h}+\\frac{f''(x)}{2}h+\\cdots\\approx\\frac{f(x)-f(x-h)}{h}$$\n",
    "\n",
    "- Adding both series together gives the **centered difference formula**\n",
    "\n",
    "    $$f'(x)=\\frac{f(x+h)-f(x-h)}{2h}-\\frac{f'''(x)}{6}h^2+\\cdots\\approx\\frac{f(x+h)-f(x-h)}{2h}$$\n",
    "\n",
    "    which is second-order accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018765b0-6d7f-4471-bd1a-728586fffe96",
   "metadata": {},
   "source": [
    "#### Approximations for the second derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea529bbb",
   "metadata": {},
   "source": [
    "- Finally, subtracting the second series from the first gives a centered difference formula for the second derivative\n",
    "\n",
    "    $$f''(x)=\\frac{f(x+h)-2f(x)+f(x-h)}{h^2}-\\frac{f^{(4)}(x)}{12}h^2+\\cdots\\approx\\frac{f(x+h)-2f(x)+f(x-h)}{h^2}$$\n",
    "\n",
    "    which is also second-order accurate.\n",
    "\n",
    "By using function values at additional points, $x \\pm 2h$, $x \\pm 3h$,$\\ldots$, we can derive similar finite difference approximations with still higher accuracy or for higher-order derivatives, although these come at a cost of more function evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c94da42-7282-421b-8a4e-f3867faf3c12",
   "metadata": {},
   "source": [
    "## Richardson Extrapolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd704b7d",
   "metadata": {},
   "source": [
    "In many problems, such as numerical integration or differentiation, we compute an approximate value for some quantity based on some step size. \n",
    "Ideally, we would like to obtain the limiting value as the step size goes to zero, but we cannot take the step size to be arbitrarily small because of excessive cost or rounding error.\n",
    "Based on values for nonzero step sizes, however, we may be able to estimate what the value would be for a step size of zero. \n",
    "Note that the extrapolated value, is still only an approximation to the exact solution, and its accuracy is still limited by the step size and arithmetic precision used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152dbf08",
   "metadata": {},
   "source": [
    "Let $F(h)$ denote the value obtained with step size $h$, using a method for which we know the scaling behavior as $h\\rightarrow 0$ (i.e. the order of the method).\n",
    "\n",
    "Starting from \n",
    "\n",
    "$$F(h)=a_0 +a_1h^p+\\mathcal{O}(h^r)$$\n",
    "\n",
    "as $h\\rightarrow 0$ for some $p$ and $r$, with $r>p$.\n",
    "\n",
    "We assume that we know the values of $p$ and $r$ from the method used to obtain $F(h)$, but not $a_0$ or $a_1$ (because $a_0=F(0)$ is the quantity we are trying to find in the first place!).\n",
    "\n",
    "Suppose that we have computed $F$ for two step sizes, say, $h$ and $h/q$ for some positive integer $q$.\n",
    "Then we have\n",
    "\n",
    "$$F(h)=a_0 +a_1h^p+\\mathcal{O}(h^r)$$\n",
    "\n",
    "and\n",
    "\n",
    "$$F(h/q)=a_0 +a_1(h/q)^p+\\mathcal{O}(h^r)=a_0 +a_1q^{-p}h^p+\\mathcal{O}(h^r)$$\n",
    "\n",
    "This system of two linear equations in the two unknowns $a_0$ and $a_1$ is easily solved\n",
    "to obtain\n",
    "\n",
    "$$a_0=F(h)+\\frac{F(h)-F(h/q)}{q^{-p}-1}+\\mathcal{O}(h^r)$$\n",
    "\n",
    "Thus, the accuracy of the improved value, $a_0$ , is $\\mathcal{O}(h^r)$ rather than $\\mathcal{O}(h^p)$.\n",
    "\n",
    "If $F(h)$ is known for several values of $h$, then the extrapolation process can be repeated to produce still more accurate approximations, up to the limitations imposed by finite-precision arithmetic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14083b21",
   "metadata": {},
   "source": [
    "> **Example**\n",
    ">\n",
    "> To illustrate Richardson extrapolation, we use it to improve the accuracy of a finite difference approximation to the derivative of the function $\\sin(x)$ at the point $x = 1$.\n",
    "> Using the first-order accurate forward difference formula (FD), we have for this problem\n",
    ">\n",
    "> $$F(h)=a_0+a_1h+\\mathcal{O}(h^2),$$\n",
    ">\n",
    "> which means that $p=1$ and $r=2$ in this case. \n",
    "Using step sizes of $h=0.5$ and $h/2=0.25$ (corresponding to $q=2$), we find\n",
    ">\n",
    "> $$\\text{FD with stepsize h: }\\frac{d\\sin(x)}{dx}\\approx\\frac{\\sin(x+h)-\\sin(x)}{h}=\\frac{\\sin(1.5)-\\sin(1)}{0.5}=0.312048=F(h)$$\n",
    ">\n",
    "> and\n",
    ">\n",
    "> $$\\text{FD with stepsize h/2: }\\frac{d\\sin(x)}{dx}\\approx\\frac{\\sin(x+h/2)-\\sin(x)}{h/2}=\\frac{\\sin(1.25)-\\sin(1)}{0.25}= 0.430055= F(h/2)$$\n",
    ">\n",
    "> The extrapolated value is then given by\n",
    ">\n",
    "> $$F(0)=a_0=F(h)+\\frac{F(h)-F(h/2)}{(1/2)-1}=2F(h/2)-F(h)=0.548061$$\n",
    ">\n",
    "> For comparison, the real result is given by $\\cos(1) \\approx 0.540302$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d379a4-0352-4b3c-be7b-50bad17459a0",
   "metadata": {},
   "source": [
    "### Romberg integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984a328f",
   "metadata": {},
   "source": [
    "Another example of Richardson extrapolation is **Romberg Integration**.\n",
    "\n",
    "Similar to the estimate of the derivative of the function at a certain value in the previous example, our strategy to estimate the value of an integral is as follows\n",
    "- Use a scheme (e.g. the composite trapezoid quadrature rule) to estimate our integral given a certain step size $h$\n",
    "- Repeat this for a second step size (for example $h/2$)\n",
    "- The two obtained values can be considered as two points $F(h)$ and $F(h/2)$ of the function $F$ whose behavior is determined by the scaling properties of the used integration scheme\n",
    "- Calculate $F(0)$ to estimate what the value of our integral would be for an infinitely small $h$\n",
    "\n",
    "> **Example**\n",
    ">\n",
    "> Consider the integral\n",
    ">\n",
    "> $$\\int_0^{\\pi/2}\\sin(x)\\,dx$$\n",
    ">\n",
    "> If we use the composite trapezoid quadrature rule, we get the following equation: (remember from the error analysis section that in the trapezoid rule the $\\mathcal{O}(h^2)$ cancel out).\n",
    ">\n",
    "> $$F(h)=a_0+a_1h^2+\\mathcal{O}(h^4)$$\n",
    ">\n",
    "> with $h=\\pi/2$, we obtain the value $F(h)=0.785398$.\n",
    "> \n",
    "> > This was obtained in the following way:\n",
    "> >\n",
    "> > The composite trapezoid rule is given by:\n",
    "> >\n",
    "> > $$\\begin{split}T_k(f)=&\\sum^k_{j=1}\\frac{x_j-x_{j-1}}{2}(f(x_{j-1})+f(x_j))\\\\\n",
    "=& h(\\frac{1}{2}f(a)+f(x_1)+\\cdots+f(x_{k-1}+\\frac{1}{2}f(b))\\end{split}$$\n",
    "> >\n",
    "> > For our specific function $\\sin(x)$ with $h=\\pi/2$ this becomes:\n",
    "> >\n",
    "> > $$F(\\pi/2)=\\frac{\\pi}{2}\\left(\\frac{1}{2}\\sin(0)+\\frac{1}{2}\\sin(\\pi/2)\\right)=0.785398$$\n",
    ">\n",
    "> Taking $q = 2$, we obtain the value $F(h/2) = F(\\pi/4) = 0.948059$.\n",
    ">\n",
    "> > This was obtained in the following way:\n",
    "> >\n",
    "> > $$F(\\pi/4)=\\frac{\\pi}{4}\\left(\\frac{1}{2}\\sin(0)+\\sin{(\\pi/4)}+\\frac{1}{2}\\sin(\\pi/2)\\right)=0.948059$$\n",
    ">\n",
    "> The extrapolated value is then given by\n",
    ">\n",
    "> $$F(0)=a_0+\\frac{F(h)-F(h/2)}{2^{-2}-1}=\\frac{4F(h/2)-F(h)}{3}=1.002280$$\n",
    ">\n",
    "> which is substantially more accurate than either value previously computed (the exact answer is 1).\n",
    ">\n",
    "\n",
    "----\n",
    "\n",
    ">\n",
    "> For any integer $k \\leq 0$, let $T_{k,0}$ denote the approximation to the integral $\\int_a^b f(x) dx$\n",
    "given by the composite trapezoid rule with step size $h_k = (b − a)/2^k$.\n",
    "> Then for any integer $j$, $j = 1,\\ldots, k$, we can recursively define the successive extrapolated values\n",
    "> \n",
    "> $$T_{k,j} =\\frac{4^jT_{k,j-1}-T_{k-1,j-1}}{4^j-1}$$\n",
    ">\n",
    "> which form a triangular array\n",
    ">\n",
    "> $$\\begin{array}\n",
    "{ccccc}\n",
    "T_{0,0}&&&&\\\\\n",
    "T_{1,0}&T_{1,1}&&&\\\\\n",
    "T_{2,0}&T_{2,1}&T_{2,2}&&\\\\\n",
    "T_{3,0}&T_{3,1}&T_{3,2}&T_{3,3}&\\\\\n",
    "\\vdots&\\vdots&\\vdots&\\vdots&\\ddots\n",
    "\\end{array}$$\n",
    ">\n",
    "> In this example we have already computed $T_{0,0} = 0.785398$, $T_{1,0} = 0.948059$, and the extrapolated value $ T_{1,1} = 1.002280$. \n",
    "> If we reduce the step size by another factor of two in the composite trapezoid rule, we obtain $T_{2,0} = F(h/4) = F(\\pi/8)$ = 0.987116. \n",
    ">\n",
    "> We can now combine the results for $h/2$ and $h/4$ to obtain the extrapolated value\n",
    ">\n",
    "> $$T_{2,1}= F(h/2)+ \\frac{F(h/2)-F(h/4)}{2^{-2}-1}=\\frac{4T_{2,0}-T_{1,0}}{4-1}=1.000135$$\n",
    ">\n",
    "> Because we have eliminated the leading $\\mathcal{O}(h^2)$ error term for the composite trapezoid rule, the accuracy of the first level of extrapolated values is $\\mathcal{O}(h^4)$. \n",
    "> Thus, we can further extrapolate on these values, but now with $p = 4$, to obtain\n",
    ">\n",
    "> $$T_{2,2}= \\frac{4^2T_{2,1}-T_{1,1}}{4^2-1}=\\frac{16 \\times 1.000135-1.002280}{15}= 0.999992$$\n",
    ">\n",
    "> which is still more accurate than any of the values computed previously.\n",
    ">\n",
    "\n",
    "----\n",
    "\n",
    "Recursive computation of extrapolated values in this manner, based on the composite trapezoid rule with successively halved step sizes, is called **Romberg integration**. \n",
    "It is capable of producing very high accuracy (up to the limit imposed by the arithmetic precision) for very smooth integrands. It is also implemented in [`scipy.integrate.romberg`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.romberg.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b2900-3eaa-4a4b-a6da-4130e29c5189",
   "metadata": {},
   "source": [
    "The same example can be solved with SciPy's `romb` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, np.pi / 2, 33)\n",
    "integrate.romb(np.sin(x), x[1] - x[0], show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302880e2-1e2b-4dad-bfac-05b7385cab36",
   "metadata": {},
   "source": [
    "## SciPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb8cbb9",
   "metadata": {},
   "source": [
    "Further information on all the functions implemented in scipy related to integration can be found here:\n",
    "[scipy.integrate](https://docs.scipy.org/doc/scipy/tutorial/integrate.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "title": "Integration and Differentiation",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "269px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
