{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import lstsq, multi_dot\n",
    "from numpy.polynomial.polynomial import Polynomial as Poly\n",
    "from scipy import linalg, optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization problems arise in all areas of science (and are perhaps even more common in engineering, business and industry). Any design does not only have a requirement that it works, but also involves the optimization of some figure of merit, like cost or efficiency. \n",
    "Out of all possible designs, we want the one that optimizes some objective.\n",
    "\n",
    "Of course, the result will depend on the objective: an engine optimized to deliver maximum power will be very different from one optimized for fuel efficiency.\n",
    "\n",
    "Next to the objective function, typically there are also some **constraints** that need to be fulfilled. For instance, when designing a bridge, we can optimize for weight or cost, but we still need to make sure it has a certain minimum strength. \n",
    "Among all feasible choices, however, we want to find the one that optimizes the cost/weight.\n",
    "\n",
    "There is also a certain duality that constraints can become objectives and vice versa. \n",
    "There is an intimate relationship between such dual problems, whose solutions are often identical. \n",
    "For example, the lightest bridge that can support a certain load, typically is the strongest bridge given its weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous description, it seems that optimization problems are mainly the concern of people who design certain objects like bridges, engines,...\n",
    "However, also physical systems evolve towards a configuration of minimum energy, which we can study using the optimization techniques found in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concepts and notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An optimization problem can be expressed mathematically as the problem of determining an argument for which a given function has an extreme value (minimum or maximum) on a given domain.\n",
    "\n",
    "Formally, given a function $f:\\mathbb{R}^n \\rightarrow \\mathbb{R}$, and a set $S\\subseteq\\mathbb{R}^n$, we seek $\\mathbf{x}^*\\in S$ such that $f$ attains a minimum on $S$ at $\\mathbf{x}^*$, i.e. $f(\\mathbf{x}^*)\\leq f(\\mathbf{x})$ for all $\\mathbf{x}\\in S$.\n",
    "\n",
    "Such a point $\\mathbf{x^*}$ is called a **minimizer**, or simply a **minimum** of $f$. A maximum of $f$ is a minimum of $-f$, so it suffices to consider minimization.\n",
    "\n",
    "The **objective function** $f$ may be linear or nonlinear, and it is usually assumed to be differentiable. \n",
    "The set $S$ is usually defined by a set of equations and inequalities, called **constraints**, which may be linear of nonlinear. \n",
    "Any vector $\\mathbf{x} \\in S$, i.e. that satisfies the constraints, is called a **feasible point**, and $S$ is called the **feasible set**. \n",
    "If $S=\\mathbb{R}^n$, the problem is **unconstrained**\n",
    "\n",
    "A general **continuous** optimization problem (note that we will not address **discrete** optimization problems) has the form\n",
    "\n",
    "$$\n",
    "\\min_{\\mathbf{x}} f(\\mathbf{x})\\quad \\text{subject to}\\quad\\mathbf{g(x)=0}\\quad \\mathrm{and}\\quad\\mathbf{h(x)\\leq0}\n",
    "$$\n",
    "\n",
    "where $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}$, $\\mathbf{g}:\\mathbb{R}^n\\rightarrow\\mathbb{R}^m$ and $\\mathbf{h}:\\mathbb{R}^n\\rightarrow\\mathbb{R}^p$.\n",
    "\n",
    "Optimization problems are classified by the properties of the functions involved. \n",
    "For example if $f$, $\\mathbf{g}$ and $\\mathbf{h}$ are all linear, then we have a **linear programming** problem. \n",
    "If any of them are nonlinear, we have a **nonlinear programming** problem. \n",
    "Note that the term programming in optimization has nothing to do with computer programming, but instead refers to planning activities in the sense of management.\n",
    "\n",
    "What constitutes a solution to an optimization problem?\n",
    "A **global minimum** satisfies $f(\\mathbf{x}^*)\\leq f(\\mathbf{x})$ for *any* feasible point $\\mathbf{x}$. \n",
    "Finding such a global minimum, or even verifying that a point is a global minimum is difficult unless the problem has special properties.\n",
    "\n",
    "Most optimization methods use local information, such as derivatives, and consequently are designed to find a **local minimum**. \n",
    "Often the best one can do to find a global minimum is use a very large set of starting points, widely scattered throughout the feasible set. \n",
    "The lowest minimum found this way has a good (but not perfect) chance of being the global minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_concept():\n",
    "    def f(x):\n",
    "        return x**2 + 10 * np.sin(x)\n",
    "\n",
    "    x = np.arange(-10, 10, 0.1)\n",
    "    plt.close(\"concept\")\n",
    "    fig, ax = plt.subplots(num=\"concept\")\n",
    "\n",
    "    # Plot the function\n",
    "    ax.plot(x, f(x), \"b-\", label=\"f(x)\")\n",
    "\n",
    "    # Plot the minima\n",
    "    xmins = np.array([-1.30641113, 3.8374671194983834])\n",
    "    ax.plot(xmins, f(xmins), \"go\", label=\"Minima\")\n",
    "\n",
    "    # Decorate the figure\n",
    "    ax.annotate(\n",
    "        \"global\\n minimum\",\n",
    "        xy=(-1.3, f(-1.3)),\n",
    "        xytext=(-1.3, 20),\n",
    "        arrowprops=dict(facecolor=\"black\", shrink=0.04),\n",
    "    )\n",
    "    ax.annotate(\n",
    "        \"local\\n minimum\",\n",
    "        xy=(3.8, f(3.8)),\n",
    "        xytext=(3.8, 60),\n",
    "        arrowprops=dict(facecolor=\"black\", shrink=0.04),\n",
    "    )\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"f(x)\")\n",
    "\n",
    "\n",
    "plot_concept()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimality conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unconstrained optimality conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **first-order necessary condition** for a minimum is that the **gradient** of the objective function $f$ is zero.\n",
    "\n",
    "$$\n",
    "\\nabla{f}(\\mathbf{x^*})=0\n",
    "$$\n",
    "\n",
    "Such an $\\mathbf{x^*}$ is called a **critical point** and the gradient is defined by \n",
    "\n",
    "$$\n",
    "\\nabla f(\\mathbf{x})=\\begin{bmatrix}\\frac{\\partial f(\\mathbf{x})}{\\partial x_1}\\\\\n",
    "\\frac{\\partial f(\\mathbf{x})}{\\partial x_2}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial f(\\mathbf{x})}{\\partial x_n}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "To understand the first-order necessary condition one should remember that the gradient always points *uphill* from $f(\\mathbf{x})$. \n",
    "Similarly, the negative gradient, $-\\nabla{f}(\\mathbf{x^*})$ always points *downhill* from $f(\\mathbf{x})$.\n",
    "Since there is no *downhill* direction at a minimum, the gradient must be zero. \n",
    "An analogous reasoning applies for a maximum. \n",
    "\n",
    "> **Equilibrium**\n",
    ">\n",
    "> Physically, the same condition corresponds to an equilibrium: a minimum of the potential energy must occur at a critical point of $V$, i.e. when $\\nabla V=0$. We recall that force is defined by the negative gradient of the potential energy:\n",
    ">\n",
    "> $$\n",
    "\\mathbf{F}(x)=-\\nabla V(x)\n",
    "$$\n",
    ">\n",
    "> Thus the negative gradient of the potential energy is zero and the system is in equilibrium when there are no net forces.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, it is necessary but not sufficient that $\\mathbf{x}$ is a critical point of $f$ for it to be a **minimum** of $f$. \n",
    "A critical point can either be a minimum, a maximum or a saddle point. \n",
    "To classify the critical points, we need another criterion.\n",
    "\n",
    "Consider the **Hessian matrix** of $f$. \n",
    "This is a matrix-valued function $\\mathbf{H}_f$ (only defined if $f$ is twice differentiable).\n",
    "\n",
    "$$\n",
    "\\mathbf{H}_f(\\mathbf{x})=\\begin{bmatrix}\n",
    "\\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_1^2}  & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_1\\partial  x_2}  & \\cdots & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_1\\partial x_n}  \\\\\n",
    "\\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_1\\partial x_2}  & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_2^2}  & \\cdots & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_2\\partial x_n}  \\\\\n",
    "\\vdots&\\vdots& \\ddots&\\vdots\\\\\n",
    "\\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_n\\partial x_1}  & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_n\\partial x_2}  & \\cdots &\\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_n^2}  \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We can then classify critical points as follows:\n",
    "\n",
    "At a critical point $\\mathbf{x}^*$, where $\\nabla f(\\mathbf{x})=\\mathbf{0}$, if $\\mathbf{H}_f(\\mathbf{x}^*)$ is...\n",
    "- Positive definite, then $\\mathbf{x}^*$ is a minimum of $f$\n",
    "- Negative definite, then $\\mathbf{x}^*$ is a maximum of $f$\n",
    "- Indefinite, then $\\mathbf{x}^*$ is a saddle point of $f$\n",
    "- Singular, then various pathological situations can occur\n",
    "\n",
    "This is called the **second-order sufficient condition**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Example**\n",
    ">\n",
    "> Consider the function\n",
    "> \n",
    "> $$\n",
    "f(\\mathbf{x})=2x^3_1+3x_1^2+12x_1x_2+3x^2_2-6x_2+6\n",
    "$$\n",
    ">\n",
    "> It's gradient is given by \n",
    ">\n",
    "> $$\n",
    "\\nabla f(\\mathbf{x})=\\begin{bmatrix}\n",
    "6x_1^2+6x_1+12x_2\\\\\n",
    "12x_1+6x_2-6\\end{bmatrix}\n",
    "$$\n",
    ">\n",
    "> Solving the nonlinear system $\\nabla f(\\mathbf{x})=0$ yields two critical points, $[1\\quad -1]^\\intercal$ and $[2\\quad -3]^\\intercal$.\n",
    ">\n",
    "> The Hessian matrix is given by\n",
    ">\n",
    "> $$\n",
    "\\mathbf{H}_f(\\mathbf{x})=\\begin{bmatrix}\n",
    "12x_1+6&12\\\\\n",
    "12&6\n",
    "\\end{bmatrix}\n",
    "$$\n",
    ">\n",
    "> Evaluating $\\mathbf{H}_f(\\mathbf{x})$ at each of the critical points gives\n",
    "> \n",
    "> $$\n",
    "\\mathbf{H}_f(1,-1)=\\begin{bmatrix}18&12\\\\12 & 6\\end{bmatrix}\n",
    "$$\n",
    ">\n",
    "> and\n",
    ">\n",
    "> $$\n",
    "\\mathbf{H}_f(2,-3)=\\begin{bmatrix}30&12\\\\12 & 6\\end{bmatrix}\n",
    "$$\n",
    ">\n",
    "> The Hessian at the first point is not positive definite (its eigenvalues are approximately 25.4 and -1.4), whereas it is positive definite at the second point (with eigenvalues of approximately 35 and 1).\n",
    ">\n",
    "> We can therefore conclude that $[1\\quad -1]^\\intercal$ is a saddle point and $[2\\quad -3]^\\intercal$ is a local minimum of $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The following cells give a visual representation of the example above.\n",
    "> First the function is defined, followed by two cell for the plots.\n",
    "> The plots show respectively a 3D and 2D graph of the function $f(\\mathbf{x})$.\n",
    "> The two critical points are explicitly marked in both graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_surface(x1, x2):\n",
    "    \"\"\"Function from the example above.\"\"\"\n",
    "    return 2 * x1**3 + 3 * x1**2 + 12 * x1 * x2 + 3 * x2**2 - 6 * x2 + 6\n",
    "\n",
    "\n",
    "def plot_example_3d():\n",
    "    # Create a meshgrid for 3D plot\n",
    "    x1 = np.linspace(-1, 3, 100)\n",
    "    x2 = np.linspace(-4, 0, 100)\n",
    "    x1, x2 = np.meshgrid(x1, x2)\n",
    "    # Compute the function and truncate high values with nan\n",
    "    # to show only the surface near the stationary points.\n",
    "    z = func_surface(x1, x2)\n",
    "    z[z > 20] = np.nan\n",
    "\n",
    "    # Create 3D plot\n",
    "    plt.close(\"example3d\")\n",
    "    fig = plt.figure(figsize=(6, 6), num=\"example3d\")\n",
    "    ax = fig.add_subplot(projection=\"3d\")\n",
    "    ax.plot_surface(x1, x2, z, cmap=\"plasma\", alpha=0.8)\n",
    "\n",
    "    # Critical points with text\n",
    "    critical_points = {\"Saddle point\": [1, -1], \"Local minimum\": [2, -3]}\n",
    "    for label, point in critical_points.items():\n",
    "        ax.scatter(*point, func_surface(*point), c=\"k\")\n",
    "        ax.text(*point, func_surface(*point), label, color=\"black\", zorder=10)\n",
    "\n",
    "    # Add labels, legend and title\n",
    "    ax.set_xlabel(\"$x_1$\", fontsize=12)\n",
    "    ax.set_ylabel(\"$x_2$\", fontsize=12)\n",
    "    ax.set_zlabel(\"f($x_1$, $x_2$)\", fontsize=12)\n",
    "\n",
    "\n",
    "plot_example_3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_2d():\n",
    "    # Create a meshgrid for 2D plot\n",
    "    x1 = np.linspace(-1, 3, 100)\n",
    "    x2 = np.linspace(-4, 0, 100)\n",
    "    x1, x2 = np.meshgrid(x1, x2)\n",
    "\n",
    "    plt.close(\"example2d\")\n",
    "    fig, ax = plt.subplots(num=\"example2d\")\n",
    "    ax.contour(x1, x2, func_surface(x1, x2), levels=30, cmap=\"plasma\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "    # Critical points with text\n",
    "    critical_points = {\"Saddle point\": [1, -1], \"Local minimum\": [2, -3]}\n",
    "    for label, point in critical_points.items():\n",
    "        plt.plot(point[0], point[1], \"ko\")\n",
    "        plt.text(point[0] + 0.1, point[1] + 0.1, label, color=\"black\", zorder=10)\n",
    "\n",
    "    # Add labels, legend and title\n",
    "    ax.set_xlabel(\"$x_1$\")\n",
    "    ax.set_ylabel(\"$x_2$\")\n",
    "\n",
    "\n",
    "plot_example_2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization in one dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The techniques used here are similar to the ones used to find the solution to one-dimensional nonlinear equations, where we used a sign change to bracket the solution.\n",
    "\n",
    "A function $f:\\mathbb{R}\\rightarrow \\mathbb{R}$ is **unimodal** on an interval $[a,b]$ if there is a unique $x^*\\in [a,b]$ such that $f(x^*)$ is the minimum value of $f$ on $[a,b]$, and for any $x_1, x_2\\in [a,b]$ with $x_1<x_2$, \n",
    "\n",
    "$x_2<x^*$ implies $f(x_1)>f(x_2)$ and $x_1>x^*$ implies $f(x_1)<f(x_2)$.\n",
    "\n",
    "Thus, $f(x)$ is strictly decreasing for $x\\leq x^*$ and strictly increasing for $x\\geq x^*$. \n",
    "This property will allow us to refine an interval containing a solution by computing sample values of the function within the interval and discarding portions of the interval according to the function values obtained, analogous to bisection for solving nonlinear equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same univariate function is used to demonstrate all the implementations below.\n",
    "You can change the definition here and rerun the examples to test the algorithms for a different case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_single(x):\n",
    "    \"\"\"The demo function.\"\"\"\n",
    "    return 0.5 - x * np.exp(-x * x)\n",
    "\n",
    "\n",
    "def func_single_p(x):\n",
    "    \"\"\"First derivative of the demo function.\"\"\"\n",
    "    return (2 * x**2 - 1) * np.exp(-x * x)\n",
    "\n",
    "\n",
    "def func_single_pp(x):\n",
    "    \"\"\"Second derivative of the demo function.\"\"\"\n",
    "    return 2 * x * (3 - 2 * x**2) * np.exp(-x * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Golden section search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $f$ is unimodal on $[a,b]$, and let $x_1,x_2\\in[a,b]$ with $x_1<x_2$. \n",
    "By comparing the function values $f(x_1)$ and $f(x_2)$ we can exclude a subinterval, either $(x_2,b]$ or $[a, x_1)$ because we know that the minimum lies within the remaining subinterval.\n",
    "\n",
    "In particular, if $f(x_1)<f(x_2)$, than the minimum cannot lie in the interval $(x2,b]$ and if on the other hand $f(x_1)>f(x_2)$ than the minimum cannot lie in the interval $[a,x_1)$.\n",
    "\n",
    "This means that we are left with a shorter interval of which we already know one function value. \n",
    "Hence, we only need to calculate one more to repeat this process until our bracket reaches a certain tolerance.\n",
    "\n",
    "To make consistent progress in reducing the length of the interval containing the minimum, each pair of points in the new interval should have the same relative position as the old pair in the old interval.\n",
    "\n",
    "To accomplish this objective, we choose the relative positions of the two points to be $\\tau$ and $1-\\tau$ , where $\\frac{\\tau}{1}=\\frac{1-\\tau}{\\tau}\\rightarrow\\tau^2=1-\\tau$, so that $\\tau=(\\sqrt(5)-1)/2\\approx0.618$ (the \"golden ratio\") and $1-\\tau\\approx 0.382$. The complete procedure converges linearly to a local minimum *if* the function is unimodal within the initial bracket.\n",
    "\n",
    "In the following cells, an algorithm for golden section search is shown, together with an example and the corresponding `scipy` command to solve the same example problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_golden(f, a, b, tol):\n",
    "    \"\"\"Illustrative implementation of the Golden Section\n",
    "    method with visualization.\"\"\"\n",
    "    brackets = [[a, b]]\n",
    "    i = 0\n",
    "    print(\"  i           x1           x2        x2-x1\")\n",
    "    print(\"---  -----------  -----------  -----------\")\n",
    "    print(f\"{0:3d}  {a:11.9f}  {b:11.9f}  {b-a:11.9f}\")\n",
    "    t = (np.sqrt(5) - 1) / 2\n",
    "    x1 = a + (1 - t) * (b - a)\n",
    "    f1 = f(x1)\n",
    "    x2 = a + t * (b - a)\n",
    "    f2 = f(x2)\n",
    "    points = [[x1, x2]]\n",
    "\n",
    "    while (b - a) > tol:\n",
    "        if f1 > f2:\n",
    "            a = x1\n",
    "            x1 = x2\n",
    "            f1 = f2\n",
    "            x2 = a + t * (b - a)\n",
    "            f2 = f(x2)\n",
    "        else:\n",
    "            b = x2\n",
    "            x2 = x1\n",
    "            f2 = f1\n",
    "            x1 = a + (1 - t) * (b - a)\n",
    "            f1 = f(x1)\n",
    "        brackets.append([a, b])\n",
    "        points.append([x1, x2])\n",
    "        i = i + 1\n",
    "        print(f\"{i:3d}  {a:11.9f}  {b:11.9f}  {b-a:11.9f}\")\n",
    "\n",
    "    return np.array(brackets), np.array(points)\n",
    "\n",
    "\n",
    "def plot_golden():\n",
    "    # Perform the Golden Section method and collect data\n",
    "    brackets, points = my_golden(func_single, a=0, b=2, tol=1e-6)\n",
    "\n",
    "    # Generate the static figure\n",
    "    t = np.linspace(0, 2, 500)\n",
    "    plt.close(\"golden\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), num=\"golden\")\n",
    "    ax.plot(t, func_single(t), label=\"Objective Function\", color=\"black\")\n",
    "\n",
    "    # Plot the brackets and points for each iteration\n",
    "    for i, (bracket, _point) in enumerate(zip(brackets, points, strict=False)):\n",
    "        ax.plot(\n",
    "            bracket,\n",
    "            [func_single(bracket[0]), func_single(bracket[1])],\n",
    "            \"r-o\",\n",
    "            label=\"Brackets\" if i == 0 else \"\",\n",
    "        )\n",
    "\n",
    "    # Highlight the final region\n",
    "    ax.axvspan(\n",
    "        brackets[-1, 0],\n",
    "        brackets[-1, 1],\n",
    "        color=\"yellow\",\n",
    "        alpha=0.3,\n",
    "        label=\"Final Interval\",\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"f(x)\")\n",
    "    ax.set_title(\"Golden Section Method Visualization\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "plot_golden()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Successive parabolic interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The golden section search for optimization is analogous to the bisection method to solve a nonlinear equation. Similarly, we do not make use of the function values, other than to compare them. \n",
    "We can do better by making better use of the function values.\n",
    "\n",
    "Fitting a straight line to two points, as in the secant method, is useless as this line does not have any minimum. Instead, we must use a polynomial with degree of at least two.\n",
    "\n",
    "The simplest such approach is **successive parabolic interpolation**, where the function is evaluated at three points, and a parabola is fitted to the resulting function values. \n",
    "The minimum of the parabola is used as a new approximate value of the minimum.\n",
    "\n",
    "A straightforward implementation in python is shown below, together with an animation of an example problem.\n",
    "\n",
    "This algorithm is not guaranteed to converge, but if it is started reasonable close to a minimum it converges superlinearly with convergence rate $r\\approx1.324$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_parabolic_iteration(f, u, v, w, tol):\n",
    "    \"\"\"Illustrative implementation of Parabolic Iteration.\"\"\"\n",
    "    i = 0\n",
    "    brackets = []\n",
    "    brackets.append([v])\n",
    "    par_points = []\n",
    "    par_points.append([u, v, w])\n",
    "    print(\"  i            v         f(v)\")\n",
    "    print(\"---  -----------  -----------\")\n",
    "    print(f\"{0:3d}  {v:11.9f}  {f(v):11.9f}\")\n",
    "    p = 1.0\n",
    "    q = 1.0\n",
    "    while (np.abs(p / q)) >= tol:\n",
    "        i = i + 1\n",
    "        p = (v - u) ** 2.0 * (f(v) - f(w)) - (v - w) ** 2.0 * (f(v) - f(u))\n",
    "        q = 2.0 * ((v - u) * (f(v) - f(w)) - (v - w) * (f(v) - f(u)))\n",
    "        u = w\n",
    "        w = v\n",
    "        v = v - p / q\n",
    "        print(f\"{i:3d}  {v:11.9f}  {f(v):11.9f}\")\n",
    "        brackets.append([v])\n",
    "        par_points.append([u, w, v])\n",
    "    return np.array(brackets), np.array(par_points)\n",
    "\n",
    "\n",
    "# find the zero crossing\n",
    "pi_results, pi_points = my_parabolic_iteration(\n",
    "    func_single, u=0.5, v=1.75, w=1.2, tol=1e-8\n",
    ")\n",
    "\n",
    "# get coefficients of parabola\n",
    "pi_coeffs = np.array(\n",
    "    [Poly.fit(points, func_single(points), 2).convert().coef for points in pi_points]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_parabolic_iteration():\n",
    "    # Generate figure\n",
    "    x = np.linspace(-0.5, 2, 500)\n",
    "    plt.close(\"parabolic\")\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10), num=\"parabolic_iteration\")\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i, ax in enumerate(axs[:4]):  # Only plot the first 4 iterations\n",
    "        if i >= len(pi_points):\n",
    "            break\n",
    "        points = pi_points[i]\n",
    "        coeffs = pi_coeffs[i]\n",
    "        parabola = coeffs[2] * x**2 + coeffs[1] * x + coeffs[0]\n",
    "\n",
    "        # Plot the function and the fitted parabola\n",
    "        ax.plot(x, func_single(x), label=\"Objective Function\", color=\"blue\")\n",
    "        ax.plot(x, parabola, \"--\", label=\"Fitted Parabola\", color=\"green\")\n",
    "\n",
    "        # Highlight the points u, w, and v\n",
    "        ax.plot(points, func_single(points), \"ro\", label=\"u, w, v\")\n",
    "        ax.axvline(\n",
    "            pi_results[i + 1][0], color=\"grey\", linestyle=\"--\", label=\"Next Minimum\"\n",
    "        )\n",
    "\n",
    "        # Labels and titles\n",
    "        ax.set_title(f\"Iteration {i + 1}\")\n",
    "        ax.set_xlabel(\"x\")\n",
    "        ax.set_ylabel(\"f(x)\")\n",
    "        ax.axhline(0, color=\"black\", linewidth=0.8)\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "\n",
    "\n",
    "plot_parabolic_iteration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the previous method, a quadratic approximation to the objective function is useful because its minimum is easy to compute. \n",
    "Instead of fitting this function, we can also obtain a local quadratic approximation based on a truncated Taylor expansion.\n",
    "\n",
    "$$\n",
    "f(x+h)\\approx f(x)+f'(x)h+\\frac{1}{2}f''(x)h^2\n",
    "$$\n",
    "\n",
    "The minimum of this function is given by $-f'(x)/f''(x)$, which we can use to find the minimum of the objective function in an iterative way.\n",
    "\n",
    "This method is equivalent to Newton's method for solving nonlinear equations, and also has a quadratic convergence rate. \n",
    "However, unless it is started sufficiently close to the desired minimum it might not converge at all, or converge to a maximum or inflection point instead.\n",
    "\n",
    "A straightforward implementation in python is shown below, together with an animation of an example problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_newton_method(f, fp, fpp, x, tol):\n",
    "    \"\"\"Illustrative implementation of the 1D Newton method.\"\"\"\n",
    "    i = 0\n",
    "    brackets = []\n",
    "    brackets.append([x])\n",
    "    print(\"  i            x         f(x)\")\n",
    "    print(\"---  -----------  -----------\")\n",
    "    print(f\"{0:3d}  {x:11.9f}  {f(x):11.9f}\")\n",
    "    diff = 1.0\n",
    "    while (np.abs(diff)) >= tol:\n",
    "        i = i + 1\n",
    "        diff = fp(x) / fpp(x)\n",
    "        x = x - diff\n",
    "        print(f\"{i:3d}  {x:11.9f}  {f(x):11.9f}\")\n",
    "        brackets.append([x])\n",
    "    return np.array(brackets)\n",
    "\n",
    "\n",
    "results = my_newton_method(\n",
    "    func_single, func_single_p, func_single_pp, x=1.0, tol=1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_newton_method():\n",
    "    x_range = np.linspace(0, 2.0, 500)\n",
    "    plt.close(\"newton_method\")\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10), num=\"newton_method\")\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Only plot the first 4 iterations\n",
    "    for i, ax in enumerate(axs[:4]):\n",
    "        if i >= len(results) - 1:\n",
    "            break\n",
    "\n",
    "        x_current = results[i][0]\n",
    "        x_next = results[i + 1][0] if i + 1 < len(results) else x_current\n",
    "\n",
    "        # Plot the function\n",
    "        ax.plot(\n",
    "            x_range, func_single(x_range), label=\"Objective Function\", color=\"blue\"\n",
    "        )\n",
    "\n",
    "        # Plot the best-fit parabola\n",
    "        f_val = func_single(x_current)\n",
    "        f_prime = func_single_p(x_current)\n",
    "        f_double_prime = func_single_pp(x_current)\n",
    "        parabola = (\n",
    "            f_val\n",
    "            + f_prime * (x_range - x_current)\n",
    "            + 0.5 * f_double_prime * (x_range - x_current) ** 2\n",
    "        )\n",
    "        ax.plot(x_range, parabola, \"--\", label=\"Best-Fit Parabola\", color=\"green\")\n",
    "\n",
    "        # Highlight the current point\n",
    "        ax.plot(x_current, func_single(x_current), \"ro\", label=\"Current x\")\n",
    "        ax.axvline(x_next, color=\"grey\", linestyle=\"--\", label=\"Next x\")\n",
    "\n",
    "        # Labels and titles\n",
    "        ax.set_title(f\"Iteration {i + 1}\")\n",
    "        ax.set_xlabel(\"x\")\n",
    "        ax.set_ylabel(\"f(x)\")\n",
    "        ax.axhline(0, color=\"black\", linewidth=0.8)\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "\n",
    "\n",
    "plot_newton_method()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensional unconstrained optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next consider multidimensional unconstrained optimization, which has a number of features in common with both one-dimensional optimization and with solving of linear equations in *n* dimensions. \n",
    "\n",
    "> Below, several optimization methods are discussed and as a two-dimensional example, the function\n",
    ">\n",
    "> $$\n",
    "f(\\mathbf{x}) = 0.5x_1^2 + x_1 + 2.5x_2^2 + 1\n",
    "$$\n",
    ">\n",
    "> will be optimized using each method. To illustrate the effectiveness of these methods, they will be compared to each other at the end of this section.\n",
    ">\n",
    "> You easily replace this test function by the more challenging Himmelblau function in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_demo_func_quadratic():\n",
    "    def func(x):\n",
    "        \"\"\"Example function to be minimized.\"\"\"\n",
    "        return 0.5 * x[0] ** 2 + x[0] + 2.5 * x[1] ** 2 + 1\n",
    "\n",
    "    def func_p(x):\n",
    "        \"\"\"Gradient of the example function.\"\"\"\n",
    "        g0 = x[0] + 1\n",
    "        g1 = 5 * x[1]\n",
    "        return np.array([g0, g1])\n",
    "\n",
    "    def func_pp(x):\n",
    "        \"\"\"The Hessian of the example function.\"\"\"\n",
    "        # Easy: just a constant matrix\n",
    "        return np.array([[1, 0], [0, 5]])\n",
    "\n",
    "    return func, func_p, func_pp\n",
    "\n",
    "\n",
    "def get_demo_func_himmelblau():\n",
    "    def func(x):\n",
    "        \"\"\"Himmelblau function.\"\"\"\n",
    "        return (x[0] ** 2 + x[1] - 11) ** 2 + (x[0] + x[1] ** 2 - 7) ** 2\n",
    "\n",
    "    def func_p(x):\n",
    "        \"\"\"Gradient of the Himmelblau function.\"\"\"\n",
    "        g0 = 4 * x[0] * (x[0] ** 2 + x[1] - 11) + 2 * (x[0] + x[1] ** 2 - 7)\n",
    "        g1 = 2 * (x[0] ** 2 + x[1] - 11) + 4 * x[1] * (x[0] + x[1] ** 2 - 7)\n",
    "        return np.array([g0, g1])\n",
    "\n",
    "    def func_pp(x):\n",
    "        \"\"\"Hessian matrix of the Himmelblau function.\"\"\"\n",
    "        h00 = 12 * x[0] ** 2 + 4 * x[1] - 42\n",
    "        h01 = 4 * x[0] + 4 * x[1]\n",
    "        h11 = 12 * x[1] ** 2 + 4 * x[0] - 26\n",
    "        return np.array([[h00, h01], [h01, h11]])\n",
    "\n",
    "    return func, func_p, func_pp\n",
    "\n",
    "\n",
    "func_multi, func_multi_p, func_multi_pp = get_demo_func_quadratic()\n",
    "# func_multi, func_multi_p, func_multi_pp = get_demo_func_himmelblau()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the result of a single case, the following `plot_opt_traj` function is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_opt_trajectory(results, num):\n",
    "    \"\"\"Plot the optimization trajectory.\"\"\"\n",
    "    plt.close(num)\n",
    "    fig, ax = plt.subplots(figsize=(8, 4), num=num)\n",
    "    x = np.linspace(-8, 8, 100)\n",
    "    y = np.linspace(-4.3, 4.3, 100)\n",
    "\n",
    "    xx, yy = np.meshgrid(x, y, sparse=False)\n",
    "    zz = func_multi(np.array([xx, yy]))\n",
    "    clevels = np.array([func_multi(results_sd[i, 0]) for i in range(10)])\n",
    "\n",
    "    ax.contour(x, y, zz, np.flip(clevels))\n",
    "    ax.plot(\n",
    "        results[:, 0, 0],\n",
    "        results[:, 0, 1],\n",
    "        \"-o\",\n",
    "        markersize=7,\n",
    "        color=\"r\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax.set_xlim(-8, 8)\n",
    "    ax.set_ylim(-4.3, 4.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogous to the golden section search for one-dimensional optimization, in direct search methods for multidimensional optimization the objective function values are only *compared* to each other. \n",
    "However, in contrast to the golden section search, they do not retain the convergence guarantee. \n",
    "\n",
    "Perhaps the best known direct search method is the one of **Nelder and Mead**. \n",
    "To seek the minimum of a function $f:\\mathbb{R}^n\\rightarrow \\mathbb{R}$, the function is first evaluated at $n+1$ starting points. \n",
    "These $n+1$ starting points form a *simplex* meaning that no three points are colinear (e.g. a simplex in two dimensions, has three points which form a triangle). \n",
    "A new point is generated along the straight line connecting the point with the highest function value (the *worst* point) and the centroid of the remaining $n$ points. \n",
    "This new point then replaces the worst point and the process is repeated until convergence. \n",
    "\n",
    "Direct search methods are especially useful for nonsmooth objective functions, for which few other methods are applicable, and they can be effective when $n$ is small, but they tend to be quite expensive when $n$ is larger than two or three. \n",
    "One advantage of direct search methods is that they can easily be parallelized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steepest Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, greater use of the objective function and its derivatives leads to faster methods. \n",
    "The negative gradient of a differentiable function $f:\\mathbb{R}^n\\rightarrow \\mathbb{R}$ points *downhill* and locally, $-\\nabla f(\\mathbf{x})$ is the direction of *steepest descent*. \n",
    "Thus, the negative gradient is a potentially fruitful direction in which to seek points having lower function values. \n",
    "\n",
    "The maximum possible benefit from movement in any downhill direction is to attain the minimum of the objective function along that direction. \n",
    "For any fixed $\\mathbf{x}$ and direction $\\mathbf{s} = -\\nabla f(\\mathbf{x})$, we can define a function $\\phi:\\mathbb{R}\\rightarrow \\mathbb{R}$: \n",
    "\n",
    "$$\n",
    "\\phi(\\alpha) = f(\\mathbf{x}+\\alpha\\mathbf{s})\n",
    "$$\n",
    "\n",
    "In this way the problem of minimizing the objective function $f$ along the direction of $\\mathbf{s}$ from $\\mathbf{x}$ is seen to be a one-dimensional optimization problem that can be solved by one of the methods discussed in the previous section. \n",
    "Once a minimum is found in a certain direction, the negative gradient is computed at this new point and the process is repeated until convergence. \n",
    "This process of minimizing an objective function only along a fixed line in $\\mathbb{R}^n$ is called a *line search*.\n",
    "\n",
    "The steepest descent method is very reliable in that it can always make progress provided the gradient is nonzero. However, as the example below will illustrate the resulting iterations can zigzag back and forth, making very slow progress. \n",
    "In general, the convergence rate of steepest descent is only linear. \n",
    "\n",
    "An implementation of the steepest descent method is shown below, together with an example in two dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_steepest_descent(f, fp, x):\n",
    "    \"\"\"Illustrative implementation of the steepest descent method.\"\"\"\n",
    "    print(\"  i        f(x)\")\n",
    "    print(\"---  ----------\")\n",
    "    print(f\"{0:3d}  {f(x):8.4e}\")\n",
    "\n",
    "    xk = []\n",
    "    xk.append([x])\n",
    "\n",
    "    for i in range(1, 10):\n",
    "        s = -fp(x)\n",
    "\n",
    "        # line search\n",
    "        res = optimize.minimize_scalar(\n",
    "            (lambda alpha, x, s: f(x + alpha * s)), [0, 1], args=(x, s), tol=1e-8\n",
    "        )\n",
    "\n",
    "        # step to minimum along line\n",
    "        x = x + res.x * s\n",
    "        xk.append([x])\n",
    "        print(f\"{i:3d}  {f(x):8.4e}\")\n",
    "\n",
    "    return np.array(xk)\n",
    "\n",
    "\n",
    "results_sd = my_steepest_descent(func_multi, func_multi_p, x=np.array([7, 1.5]))\n",
    "plot_opt_trajectory(results_sd, \"steepest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton's Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A broader view of the objective function can, once again, be gained from a local quadratic approximation, which can be obtained from a truncated Taylor series expansion\n",
    "\n",
    "$$\n",
    "    f(\\mathbf{x} + \\mathbf{s}) \\approx f(\\mathbf{x}) + \\nabla f(\\mathbf{x})^\\intercal\\mathbf{s} + \\frac{1}{2}\\mathbf{s}^\\intercal \\mathbf{H}_{f}(\\mathbf{x})\\mathbf{s}, \n",
    "$$\n",
    "\n",
    "\n",
    "where $\\mathbf{H}_f(\\mathbf{x})$ is the *Hessian matrix*. \n",
    "This quadratic function in $\\mathbf{s}$ is minimized when \n",
    "\n",
    "$$\n",
    "    \\mathbf{H}_f(\\mathbf{x})\\mathbf{s} = -\\nabla f(\\mathbf{x}).\n",
    "$$\n",
    "\n",
    "The convergence rate of Newton's method for unconstrained optimization is normally quadratic but the method is unreliable unless started close enough to the solution. \n",
    "While Newton's method does not require a line search, it may still be advisable to perform a line search along the direction of the Newton step in order to make the method more robust.\n",
    "\n",
    "Below, Newton's method is applied to the same two-dimensional example as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_newton_method_nd(f, fp, fpp, x):\n",
    "    \"\"\"Illustrative implementation of the multi-dimensional Newton method.\"\"\"\n",
    "    print(\"  i        f(x)\")\n",
    "    print(\"---  ----------\")\n",
    "    print(f\"{0:3d}  {f(x):8.4e}\")\n",
    "\n",
    "    xk = []\n",
    "    xk.append([x])\n",
    "\n",
    "    for i in range(1, 10):\n",
    "        # solve linear system\n",
    "        hessian = fpp(x)\n",
    "        s = linalg.solve(hessian, -fp(x))\n",
    "\n",
    "        # make step\n",
    "        x = x + s\n",
    "        xk.append([x])\n",
    "        print(f\"{i:3d}  {f(x):8.4e}\")\n",
    "\n",
    "    return np.array(xk)\n",
    "\n",
    "\n",
    "results_nm = my_newton_method_nd(\n",
    "    func_multi, func_multi_p, func_multi_pp, x=np.array([7, 1.5])\n",
    ")\n",
    "plot_opt_trajectory(results_nm, \"newton_nd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quasi-Newton Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newton's method usually converges very rapidly once it nears a solution, but it requires a substantial amount of work per iteration. \n",
    "Specifically, for a problem with a dense Hessian matrix, each iteration requires $\\mathcal{O}(n^2)$ scalar function evaluations to form the gradient and the Hessian matrix while $\\mathcal{O}(n^3)$ arithmetic operations are required to solve the linear system for the Newton step. \n",
    "Many variants of Newton's method have been developed to reduce its overhead or improve its reliability, or both. These *quasi-Newton methods* have the general form\n",
    "\n",
    "$$\n",
    "    \\mathbf{x}_{k+1} = \\mathbf{x}_{k} - \\alpha_k\\mathbf{B}^{-1}_k\\nabla f(\\mathbf{x}_{k})\n",
    "$$\n",
    "\n",
    "where $\\alpha_k$ is a line search parameter and $\\mathbf{B}_k$ is some approximation of the Hessian matrix obtained in any number of ways, including secant updating, finite differences, periodic reevaluation, or neglecting some terms in the true Hessian of the objective function. \n",
    "\n",
    "Many quasi-Newton methods are more robust than the pure Newton method and have considerably lower overhead per iteration yet remain superlinear (though not quadratic). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secant Updating Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several secant updating formulas for unconstrained minimization have been developed that not only preserve symmetry in the approximate Hessian matrix but also preserve positive definiteness. \n",
    "Symmetry reduces the amount of work and storage required by about half, and positive definiteness guarantees that the resulting quasi-Newton step will be a descent direction. \n",
    "In practice, a factorization of $\\mathbf{B}_k$ is updated rather than $\\mathbf{B}_k$ itself, so that the linear system for the quasi-Newton step can be solved at a cost per iteration of $\\mathcal{O}(n^2)$ rather than $\\mathcal{O}(n^3)$ operations. \n",
    "\n",
    "Unlike Newton's method for optimization, no second derivatives are required. \n",
    "And most of these methods are often started with $\\mathbf{B}_0 = \\mathbf{I}$, which means the first step is along the negative gradient (i.e. along the direction of steepest descent) and then second derivative information is gradually built up in the approximate Hessian matrix by updating over successive iterations. \n",
    "\n",
    "One of the most effective secant updating methods for optimization is called BFGS of which an implementation is shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_bfgs(f, fp, B, x):\n",
    "    \"\"\"Illustrative implementation of the BFGS Quasi Newton method.\"\"\"\n",
    "\n",
    "    print(\"  i        f(x)\")\n",
    "    print(\"---  ----------\")\n",
    "    print(f\"{0:3d}  {f(x):8.4e}\")\n",
    "\n",
    "    xk = []\n",
    "    xk.append([x])\n",
    "    tol = 1e-8\n",
    "    y = 1\n",
    "    s = 1\n",
    "    i = 0\n",
    "\n",
    "    while (np.dot(y, s)) >= tol:\n",
    "        i += 1\n",
    "        # solve linear system + make step (cfr. Newton's Method)\n",
    "        s = linalg.solve(B, -fp(x))\n",
    "        x_new = x + s\n",
    "\n",
    "        # update approximation of Hessian\n",
    "        y = fp(x_new) - fp(x)\n",
    "        B = (\n",
    "            B\n",
    "            + (np.outer(y, y) / np.dot(y, s))\n",
    "            - (np.dot(np.outer(np.dot(B, s), s), B) / multi_dot([s, B, s]))\n",
    "        )  # update B with BFGS formula\n",
    "\n",
    "        x = x_new\n",
    "        xk.append([x])\n",
    "        print(f\"{i:3d}  {f(x):8.4e}\")\n",
    "\n",
    "    return np.array(xk)\n",
    "\n",
    "\n",
    "# initial guess B = I\n",
    "results_bfgs = my_bfgs(\n",
    "    func_multi, func_multi_p, B=np.array([[1, 0], [0, 1]]), x=np.array([7, 1.5])\n",
    ")\n",
    "plot_opt_trajectory(results_bfgs, \"bfgs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the increase in function value on the first iteration in the example above could have been avoided by using a line search. \n",
    "Such a line search can also be used to enhance the effectiveness of the method. \n",
    "For a quadratic expression it can be stated that if an exact line search is added to every iteration of the BFGS method, it will terminate at the exact solution after at most $n$ iterations, where $n$ is the dimension of the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjugate Gradient Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conjugate gradient method is another alternative to Newton's method that does not require explicit second derivatives. \n",
    "Indeed, unlike secant updating methods, the conjugate gradient method does not even store an approximation to the Hessian matrix, which makes it especially **suitable for very large problems**. \n",
    "\n",
    "As the name suggests, the conjugate gradient method also uses gradients, but in contrast to the steepest descent method it avoids repeatedly searching in the same directions by modifying the new gradient at each step to remove components in previous directions. \n",
    "The resulting sequence of *conjugate* (i.e. orthogonal in the inner product $(\\mathbf{x},\\mathbf{y}) = \\mathbf{x}^\\intercal\\mathbf{H}_f\\mathbf{y}$ search directions implicitly accumulates information about the Hessian matrix as iterations proceed. \n",
    "\n",
    "Theoretically, the conjugate gradient method is exact after at most $n$ iterations for a quadratic objective function in $n$ dimensions, but it is usually quite effective for more general unconstrained optimization problems as well. \n",
    "It is common to restart the algorithm after every $n$ iterations by restarting to use the negative gradient at the current point. \n",
    "\n",
    "In the following example, an implementation of the conjugate gradient method is applied to minimize a function in two dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_conjugate_gradient(f, fp, x):\n",
    "    \"\"\"Illustrative implementation of the conjugate gradient method.\"\"\"\n",
    "    print(\"  i        f(x)\")\n",
    "    print(\"---  ----------\")\n",
    "    print(f\"{0:3d}  {f(x):8.4e}\")\n",
    "\n",
    "    xk = []\n",
    "    xk.append([x])\n",
    "\n",
    "    # initialize parameters\n",
    "    g = fp(x)\n",
    "    s = -g\n",
    "    for i in range(1, 5):\n",
    "        # line search + make step\n",
    "        res = optimize.minimize_scalar(\n",
    "            (lambda alpha, x, s: f(x + alpha * s)), [0, 1], args=(x, s), tol=1e-8\n",
    "        )\n",
    "        x_new = x + res.x * s\n",
    "\n",
    "        g_new = fp(x_new)\n",
    "        # Polak-Ribiere with built-in reset\n",
    "        b = max(np.inner(g_new - g, g_new) / np.inner(g, g), 0)\n",
    "        s = -g_new + b * s\n",
    "\n",
    "        x = x_new\n",
    "        g = g_new\n",
    "\n",
    "        xk.append([x])\n",
    "        print(f\"{i:3d}  {f(x):8.4e}\")\n",
    "\n",
    "    return np.array(xk)\n",
    "\n",
    "\n",
    "results_cg = my_conjugate_gradient(func_multi, func_multi_p, x=np.array([7, 1.5]))\n",
    "plot_opt_trajectory(results_cg, \"cg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Least squares data fitting can be viewed as an optimization problem. \n",
    "Given data points $(t_i,y_i), i = 1,\\dots,m$, we wish to find the vector $\\mathbf{x} \\in \\mathbb{R}^n$ of parameters that gives the best fit to the model function $f(t,\\mathbf{x})$, where $f:\\mathbb{R}^{n+1} \\rightarrow \\mathbb{R}$. \n",
    "Previously, we only considered cases in which the model function $f$ was linear in the components of $\\mathbf{x}$ but now we are in a position to consider *nonlinear least squares* as a special case of nonlinear optimization. \n",
    "\n",
    "If we define the components of the *residual* function $\\mathbf{r}:\\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ by \n",
    "\n",
    "$$\n",
    "r_i(\\mathbf{x}) = y_i - f(t_i,\\mathbf{x}), \\quad i = 1,\\dots,m,\n",
    "$$\n",
    "\n",
    "then we wish to minimize the function\n",
    "\n",
    "$$\n",
    "\\phi(\\mathbf{x}) = \\frac{1}{2}\\mathbf{r}(\\mathbf{x})^\\intercal\\mathbf{r}(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "i.e. the sum of squares of the residual components (the factor 1/2 is inserted for later convenience and has no effect on the optimal value for $\\mathbf{x}$). \n",
    "If we apply Newton's method and $\\mathbf{x}_k$ is an approximate solution, then the Newton step $\\mathbf{s}_k$ is given by the linear system \n",
    "\n",
    "$$\n",
    "\\mathbf{H}_\\phi(\\mathbf{x}_k)\\mathbf{s}_k = -\\nabla\\phi(\\mathbf{x}_k)\n",
    "$$\n",
    "\n",
    "\n",
    "where the gradient vector and Hessian matrix of $\\phi$ are given by\n",
    "\n",
    "$$\n",
    "\\nabla\\phi(\\mathbf{x}) = \\mathbf{J}^\\intercal(\\mathbf{x})\\mathbf{r}(\\mathbf{x})\n",
    "$$\n",
    "and \n",
    "\n",
    "$$\n",
    "\\mathbf{H}_\\phi(\\mathbf{x}) = \\mathbf{J}^\\intercal(\\mathbf{x})\\mathbf{J}(\\mathbf{x}) + \\sum_{i=1}^{m}r_i(\\mathbf{x})\\mathbf{H}_{r_i}(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "in which $\\mathbf{J}^\\intercal(\\mathbf{x})$ is the Jacobian matrix of $\\mathbf{r}(\\mathbf{x})$, and $\\mathbf{H}_{r_i}(\\mathbf{x})$ denotes the Hessian matrix of the component function $r_i(\\mathbf{x})$. \n",
    "\n",
    "The Newton step $\\mathbf{s}_k$ is thus given by the linear system\n",
    "\n",
    "$$\n",
    "\\left(\\mathbf{J}^\\intercal(\\mathbf{x}_k)\\mathbf{J}(\\mathbf{x}_k) + \\sum_{i=1}^{m}r_i(\\mathbf{x}_k)\\mathbf{H}_{r_i}(\\mathbf{x}_k)\\right)\\mathbf{s}_k = -\\mathbf{J}^\\intercal(\\mathbf{x}_k)\\mathbf{r}(\\mathbf{x}_k)\n",
    "$$\n",
    "\n",
    "The $m$ Hessian matrices $\\mathbf{H}_{r_i}$ of the residual components are usually inconvenient and expensive to compute. Fortunately, we can exploit the special structure of this problem to avoid computing them in most cases, as we will see next. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gauss-Newton Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in $\\mathbf{H}_\\phi$  each of the Hessian matrices $\\mathbf{H}_{r_i}$ is multiplied by the corresponding residual component $r_i$, which should be small at a solution, provided that the model function fits the data reasonably well. This observation motivates the *Gauss-Newton method* for nonlinear least squares in which the terms involving $\\mathbf{H}_{r_i}$ are dropped from the Hessian and the linear system \n",
    "\n",
    "$$\n",
    "\\left(\\mathbf{J}^\\intercal(\\mathbf{x}_k)\\mathbf{J}(\\mathbf{x}_k)\\right)\\mathbf{s}_k = -\\mathbf{J}^\\intercal(\\mathbf{x}_k)\\mathbf{r}(\\mathbf{x}_k)\n",
    "$$\n",
    "\n",
    "determines an approximate Newton step $\\mathbf{s}_k$ at each iteration.\n",
    "\n",
    "We recognize this system as the normal equations for the $m\\times n$ linear least squares problem\n",
    "\n",
    "$$\n",
    "\\mathbf{J}(\\mathbf{x}_k)\\mathbf{s}_k \\cong -\\mathbf{r}(\\mathbf{x}_k)\n",
    "$$\n",
    "\n",
    "which can be solved more reliably by orthogonal factorization of $\\mathbf{J}(\\mathbf{x}_k)$. \n",
    "The next approximate solution is then given by $\\mathbf{x}_{k+1} = \\mathbf{x}_k+\\mathbf{s}_k$ and the process is repeated until convergence. \n",
    "In effect, the Gauss-Newton method replaces a nonlinear least squares problem by a sequence of linear least squares problems whose solutions converge to the solution of the original nonlinear problem. \n",
    "\n",
    "If the residual components at the solution are relatively large, then the terms omitted from the Hessian matrix may not be negligible, in which case the Gauss-Newton approximation may be inaccurate and convergence is no longer guaranteed. \n",
    "In such cases, it may be best to use a general nonlinear optimization method that takes into account the full Hessian matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Example: radioactive decay**\n",
    ">\n",
    "> As an example the Gauss-Newton method will be used to fit the time dependency of the measured activity of a radioactive Fermium-246 sample. \n",
    "> The experiment yielded the following four data points\n",
    ">\n",
    "> | t (s) | A (s$^{-1}$) |\n",
    "> |:-----:|:----------:|\n",
    "> |  0.0  |     514    |\n",
    "> |  1.0  |     303    |\n",
    "> |  2.0  |     201    |\n",
    "> |  3.0  |     113    |\n",
    ">\n",
    "> and the model prescription has the form\n",
    ">\n",
    "> $$\n",
    "f(t,\\mathbf{x}) =  x_1e^{x_2t} =  A_0e^{-\\lambda t} ,\n",
    "$$\n",
    ">\n",
    "> where $x_1 = A_0$ is the initial activity of the sample and $x_2 = -\\lambda$ is the decay constant of the radioactive isotope which is closely related to the half-life constant.  \n",
    ">\n",
    "> For this model function, the entries of the Jacobian matrix of the residual function $\\mathbf{r}$ are given by\n",
    ">\n",
    "> $$\n",
    "\\{\\mathbf{J}(\\mathbf{x})\\}_{i,1} = \\frac{\\partial r_i(\\mathbf{x})}{\\partial x_1} = -e^{x_2t_i}, \\qquad \\{\\mathbf{J}(\\mathbf{x})\\}_{i,2} = \\frac{\\partial r_i(\\mathbf{x})}{\\partial x_2} = -x_1t_ie^{x_2t_i}\n",
    "$$\n",
    "> \n",
    "> where the minus sign originates from the definition of $\\mathbf{r}\\  (=A_i-f(t_i,\\mathbf{x}))$  and $i = 1,\\dots,4$. If we start with $\\mathbf{x}_0 = [480,\\ \\ -0.4]^\\intercal$ as the initial guess, then the linear least squares problem to be solved for the Gauss-Newton step $\\mathbf{s}_0$ is\n",
    ">\n",
    "> $$\n",
    "\\mathbf{J}(\\mathbf{x}_0)\\mathbf{s}_0 = \n",
    "\\begin{bmatrix}\n",
    "-1.00 & 0 \\\\\n",
    "-0.67 & -322 \\\\\n",
    "-0.45 & -431 \\\\\n",
    "-0.30 & -434\n",
    "\\end{bmatrix} \\mathbf{s}_0 \\cong \n",
    "\\begin{bmatrix}\n",
    "-34.00 \\\\\n",
    "\\hphantom{-}18.75 \\\\\n",
    "\\hphantom{-}14.68 \\\\\n",
    "\\hphantom{-}31.57\n",
    "\\end{bmatrix} = -\\mathbf{r}(\\mathbf{x}_0)     \n",
    "$$\n",
    ">\n",
    "> The least squares solution of this system is $\\mathbf{s}_0 = [30.75,\\ \\ -0.089]^\\intercal$ and hence we take $\\mathbf{x}_1 = \\mathbf{x}_0 + \\mathbf{s}_0 = [510.75,\\ \\ -0.489]^\\intercal$ for the next step. \n",
    "> As illustrated in the implementation below, the system converges after several iterations. \n",
    "> From the decay constant $\\lambda = -x_2$ the half-life of Fermium-246 can be calculated according to \n",
    ">\n",
    "> $$\n",
    "T_{1/2} = \\frac{\\ln(2)}{\\lambda} = \\frac{\\ln(2)}{0.494} = 1.4 s\n",
    "$$\n",
    ">\n",
    "> which is indeed very close to the actual half-life of 1.5 s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radioactiveModel(t, x):\n",
    "    \"\"\"model function\"\"\"\n",
    "    return x[0] * np.exp(x[1] * t)\n",
    "\n",
    "\n",
    "def jacobian(t, x):\n",
    "    \"\"\"Jacobian matrix of r(x)\"\"\"\n",
    "    J1 = -np.exp(x[1] * t)\n",
    "    J2 = -x[0] * t * np.exp(x[1] * t)\n",
    "\n",
    "    return np.array([J1, J2]).T\n",
    "\n",
    "\n",
    "def residual(t, y, x):\n",
    "    return np.array(y - radioactiveModel(t, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nonlinear least squares fitting using Gauss-Newton method\n",
    "def gauss_newton_static_plot(initial_guess):\n",
    "    t = np.arange(0, 4)\n",
    "    y = np.array([514, 303, 201, 113])\n",
    "    x = np.array(initial_guess)\n",
    "\n",
    "    iterations = []\n",
    "    models = []\n",
    "    residuals = []\n",
    "\n",
    "    print(\"Iteration    Parameters (x1, x2)               Squared Sum of Residuals\")\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "    for i in range(5):  # Perform 5 iterations\n",
    "        iterations.append(x.copy())\n",
    "        models.append(radioactiveModel(t, x))\n",
    "        r = residual(t, y, x)\n",
    "        residuals.append(np.sum(r**2))  # Calculate squared sum of residuals\n",
    "\n",
    "        print(\n",
    "            f\"{i + 1:>4}        {x[0]:>10.4f}, {x[1]:>10.4f}         \"\n",
    "            f\"{residuals[-1]:>20.4f}\"\n",
    "        )\n",
    "\n",
    "        J = jacobian(t, x)\n",
    "        p, _, _, _ = lstsq(J, -r, rcond=None)\n",
    "        x = x + p\n",
    "\n",
    "    # Generate the static plot\n",
    "    plt.close(\"gauss_newton\")\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(15, 10), num=\"gauss_newton\")\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    t_fine = np.linspace(0, 3, 100)\n",
    "    for i, ax in enumerate(axs[:5]):\n",
    "        ax.scatter(t, y, label=\"Data points\", color=\"black\")\n",
    "        ax.plot(\n",
    "            t_fine,\n",
    "            radioactiveModel(t_fine, iterations[i]),\n",
    "            label=f\"Iteration {i + 1}\",\n",
    "            color=\"blue\",\n",
    "        )\n",
    "        ax.set_title(\n",
    "            f\"Iteration {i + 1}: x = {iterations[i]}\\n\"\n",
    "            f\"Sum of Residuals^2: {residuals[i]:.4f}\"\n",
    "        )\n",
    "        ax.set_xlabel(\"Time (t)\")\n",
    "        ax.set_ylabel(\"Radioactivity\")\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "\n",
    "    # Hide the last unused subplot\n",
    "    axs[-1].axis(\"off\")\n",
    "\n",
    "\n",
    "# Call the function to generate the static plot\n",
    "gauss_newton_static_plot([480, -0.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all methods based on Newton's method, the Gauss-Newton method for solving nonlinear least squares problems may fail to converge unless it is started sufficiently close to the solution. \n",
    "A line search can be used to improve its robustness, but additional modifications may be necessary to ensure that the computed step $\\mathbf{s}_k$ is a descent direction when far from the solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levenberg-Marquardt Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Levenberg-Marquardt method* is a useful alternative when the Gauss-Newton method yields an ill-conditioned or rank-deficient linear least squares subproblem. \n",
    "At each iteration of this method, the linear system for the step $\\mathbf{s}_k$ is of the form\n",
    "\n",
    "$$\n",
    "\\left(\\mathbf{J}^\\intercal(\\mathbf{x}_k)\\mathbf{J}(\\mathbf{x}_k) + \\mu_k\\mathbf{I}\\right)\\mathbf{s}_k = -\\mathbf{J}^\\intercal(\\mathbf{x}_k)\\mathbf{r}(\\mathbf{x}_k)\n",
    "$$\n",
    "\n",
    "where $\\mu_k$ is a nonnegative scalar parameter chosen by some strategy. The corresponding linear least squares problem to be solved is \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    \\mathbf{J}(\\mathbf{x}_k)\\\\\n",
    "    \\sqrt{\\mu_k}\\ \\mathbf{I}\n",
    "\\end{bmatrix}  \\mathbf{s}_k \\cong \n",
    "\\begin{bmatrix}\n",
    "    -\\mathbf{r}(\\mathbf{x}_k)\\\\\n",
    "    \\mathbf{0}\n",
    "\\end{bmatrix}  \n",
    "$$\n",
    "\n",
    "This method can be interpreted as replacing the terms omitted from\n",
    "the true Hessian by a scalar multiple of the identity matrix or as using a\n",
    "weighted combination of the Gauss-Newton step and the steepest descent direction. \n",
    "With a suitable strategy for choosing the parameter $\\mu_k$, typically based on a trust-region approach, the Levenberg-Marquardt method can be very robust in practice, and it forms the basis for several effective software packages for solving nonlinear least squares problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constrained optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we only considered minima that occur at an interior point of the feasible set $S$. \n",
    "For **constrained optimization problems**, the minimum is often located outside the feasible set, meaning that the solution of the constrained optimization problem occurs on the boundary of the feasible set. \n",
    "The principles to find a minimum remains the same: a minimum occurs at $\\mathbf{x}^*\\in S$ when there is no downhill direction starting from $\\mathbf{x}^*$, considering only **feasible directions**, i.e. directions for which the constraints continue to be satisfied. \n",
    "\n",
    "In general, the constraints can be linear or nonlinear and can be subdivided into the following two categories: \n",
    "\n",
    "* **Equality constraints** which are of the general form $\\mathbf{g}(\\mathbf{x}) = \\mathbf{0}$\n",
    "* **Inequality constraints** which are of the general form $\\mathbf{h}(\\mathbf{x}) \\leq \\mathbf{0}$\n",
    "\n",
    "Inequality constraints may be irrelevant to the solution and a given inequality constraint $h_i(\\mathbf{x}) \\leq 0$ is said to be *active* or *binding* at a feasible point $\\mathbf{x} \\in \\mathbf{S}$ if $h_i(\\mathbf{x}) = 0$. Naturally, equality constraints are always active. \n",
    "\n",
    "Both equality-constrained and inequality-constrained problems can be solved using *Lagrange multipliers* although the optimality conditions become more complicated when inequality constraints are involved. \n",
    "\n",
    "> **Example: the Rosenbrock function**\n",
    ">\n",
    "> As an example, let us consider minimization of the Rosenbrock function\n",
    ">\n",
    "> $$\n",
    "\\min_{x_0,x_1}\\ \\left(100\\ (x_1-x_0^2)^2 + (1 - x_0)^2\\right)\n",
    "$$\n",
    ">\n",
    "> under the condition that the following constraints apply:\n",
    ">\n",
    "> $$\\begin{aligned}\n",
    "x_0 + 2x_1 &\\leq 1 \\\\\n",
    "x_0^2 + x_1 &\\leq 1\\\\\n",
    "x_0^2 - x_1 &\\leq 1\\\\\n",
    "2x_0 + x_1 &= 1\\\\\n",
    "0 \\leq x_0 &\\leq 1\\\\\n",
    "-0.5 \\leq x_1 &\\leq 2\n",
    "\\end{aligned}$$\n",
    "> \n",
    "> This constrained optimization problem has a unique solution $\\mathbf{x}^* = [0.4149\\quad 0.1701]^\\intercal$ for which only the fourth constraint is active.\n",
    "> Note, however, that the Rosenbrock function has a global minimum at $\\mathbf{x}' = [1\\\n",
    "1]^\\intercal$ but that this point is not a feasible point $\\left(\\mathbf{x'} \\notin \\mathbf{S}\\right)$ because it violates multiple constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The trust-region constrained algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimize function of `scipy.optimize` provides several algorithms for constrained minimization. \n",
    "One of which is the trust-region constrained algorithm, which deals with constrained minimization problems of the form:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\min_{\\mathbf{x}} f(\\mathbf{x}) \\\\\n",
    "& \\begin{aligned}\n",
    "\\text{subject to:} \\quad&\\mathbf{c}_l \\leq \\mathbf{c}(\\mathbf{x}) \\leq \\mathbf{c}_u \\\\\n",
    " & \\mathbf{x}_l \\leq \\mathbf{x} \\leq \\mathbf{x}_u\n",
    "\\end{aligned}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "When $c_{l,j} = c_{u,j}$ the method reads the $j$<sup>th</sup> constraint as an equality constraint and deals with it accordingly. \n",
    "Besides that, one-sided constraints can be specified by setting the upper ($u$) or lower ($l$) bound to `np.inf` with the appropriate sign. \n",
    "As an illustration, this method will be applied to the Rosenbrock example. \n",
    "\n",
    "> **Example: the trust-region constrained algorithm**\n",
    "> The method requires the constraints to be defined as a sequence of Bounds, LinearConstraint and NonlinearConstraint objects. \n",
    "Therefore the first step is to classify the constraints from the above example accordingly. \n",
    "> - There are two *bound constraints*, namely $0 \\leq x_0 \\leq 1$ and \n",
    "$-0.5 \\leq x_1 \\leq 2$.\n",
    "> - There are two *linear constraints*, namely $x_0 + 2x_1 \\leq 1$ and $2x_0 + x_1 = 1$\n",
    "> - There are two *nonlinear constraints*, namely $x_0^2 + x_1 \\leq 1$ and $x_0^2 - x_1 \\leq 1$.\n",
    ">\n",
    "> The linear constraints can be written in the standard format\n",
    ">\n",
    "> $$\n",
    "\\begin{bmatrix}\n",
    "-\\infty \\\\ 1\n",
    "\\end{bmatrix}\\leq \n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "2 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_0 \\\\ x_1\n",
    "\\end{bmatrix}\\leq\n",
    "\\begin{bmatrix}\n",
    "1 \\\\ 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    ">\n",
    "> Whereas the nonlinear constraints can be written as\n",
    ">\n",
    "> $$\n",
    "\\begin{bmatrix}\n",
    "-\\infty  \\\\ -\\infty\n",
    "\\end{bmatrix}\\leq \n",
    "\\begin{bmatrix}\n",
    "x_0^2+x_1 \\\\ x_0^2-x_1\n",
    "\\end{bmatrix}\n",
    "= \\mathbf{c}(\\mathbf{x})\n",
    "\\leq\n",
    "\\begin{bmatrix}\n",
    "1 \\\\ 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    ">\n",
    "> The NonlinearConstraints object also takes the Jacobian matrix and a linear combination of Hessians of $\\mathbf{c}(\\mathbf{x})$ as optional arguments. \n",
    "If no Jacobian matrix or Hessian is passed, the gradient will be estimated using 2-point finite difference estimation with an absolute step size while the Hessian will be estimated using one of the quasi-Newton strategies. \n",
    "However, for this example they can be calculated with relative ease which gives: \n",
    ">\n",
    "> $$\n",
    "\\mathbf{J}(\\mathbf{x}) = \n",
    "\\begin{bmatrix}\n",
    "2x_0 & 1 \\\\\n",
    "2x_0 & -1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    ">\n",
    "> $$\n",
    "\\mathbf{H}(\\mathbf{x},\\mathbf{v}) = \\sum_{i} v_i\\nabla^2c_i(\\mathbf{x}) = \n",
    "v_0\\begin{bmatrix}\n",
    "2 & 0 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix} + \n",
    "v_1\\begin{bmatrix}\n",
    "2 & 0 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    ">\n",
    "> With this information it is now possible to solve the constrained optimization problem with `scipy.optimize.minimize` as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosen(x):\n",
    "    return sum(100.0 * (x[1:] - x[:-1] ** 2.0) ** 2.0 + (1 - x[:-1]) ** 2.0)\n",
    "\n",
    "\n",
    "def cons_c(x):\n",
    "    return [x[0] ** 2 + x[1], x[0] ** 2 - x[1]]\n",
    "\n",
    "\n",
    "def cons_J(x):\n",
    "    return [[2 * x[0], 1], [2 * x[0], -1]]\n",
    "\n",
    "\n",
    "def cons_H(x, v):\n",
    "    return v[0] * np.array([[2, 0], [0, 0]]) + v[1] * np.array([[2, 0], [0, 0]])\n",
    "\n",
    "\n",
    "# Initialize constraint objects\n",
    "bounds = optimize.Bounds([0, -0.5], [1.0, 2.0])\n",
    "linear_constraint = optimize.LinearConstraint([[1, 2], [2, 1]], [-np.inf, 1], [1, 1])\n",
    "nonlinear_constraint = optimize.NonlinearConstraint(\n",
    "    cons_c, -np.inf, 1, jac=cons_J, hess=cons_H\n",
    ")\n",
    "\n",
    "# Solve the optimization\n",
    "x0 = np.array([0.5, 0])  # initial guess\n",
    "res = optimize.minimize(\n",
    "    rosen,\n",
    "    x0,\n",
    "    method=\"trust-constr\",\n",
    "    constraints=[linear_constraint, nonlinear_constraint],\n",
    "    bounds=bounds,\n",
    ")\n",
    "\n",
    "print(\"Result: \", res.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which indeed corresponds to the expected solution of $\\mathbf{x}^* = [0.4149\\quad 0.1701]^\\intercal$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rosen(less_busy=False):\n",
    "    \"\"\"Plot Rosenbrock function with constraints and (constrained) minimum.\"\"\"\n",
    "\n",
    "    # Define the Rosenbrock function and its constraints\n",
    "    def Rosen(x, y):\n",
    "        return (1 - x) ** 2 + 100.0 * (y - x**2) ** 2\n",
    "\n",
    "    def constraint_1(x, y):\n",
    "        return x - 2 * y - 1  # Reformulated as a <= 0\n",
    "\n",
    "    def constraint_2(x, y):\n",
    "        return x**2 + y - 1  # Reformulated as a <= 0\n",
    "\n",
    "    def constraint_3(x, y):\n",
    "        return x**2 - y - 1  # Reformulated as a <= 0\n",
    "\n",
    "    def constraint_4(x, y):\n",
    "        return 2 * x + y - 1  # Reformulated as a <= 0\n",
    "\n",
    "    def constraint_5a(x, y):\n",
    "        return x - 1  # Reformulated as a <= 0\n",
    "\n",
    "    def constraint_5b(x, y):\n",
    "        return -x  # Reformulated as a <= 0\n",
    "\n",
    "    def constraint_6a(x, y):\n",
    "        return y - 1  # Reformulated as a <= 0\n",
    "\n",
    "    def constraint_6b(x, y):\n",
    "        return -y - 0.5  # Reformulated as a <= 0\n",
    "\n",
    "    # Define grid\n",
    "    x = np.linspace(-2.0, 2.0, 300)\n",
    "    y = np.linspace(-1.0, 3.0, 300)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "    # Plot Rosenbrock function\n",
    "    plt.close(\"rosen\")\n",
    "    fig, ax = plt.subplots(num=\"rosen\")\n",
    "    cm = ax.contourf(\n",
    "        xx, yy, Rosen(xx, yy), 20, cmap=\"viridis\", alpha=0.7 if less_busy else 1\n",
    "    )\n",
    "    plt.colorbar(cm)\n",
    "\n",
    "    # Add contour lines\n",
    "    ax.contour(xx, yy, np.log(Rosen(xx, yy)), 20, colors=\"black\", linewidths=1.0)\n",
    "\n",
    "    # Plot constraints\n",
    "    constraints = [\n",
    "        constraint_1,\n",
    "        constraint_2,\n",
    "        constraint_3,\n",
    "        constraint_4,\n",
    "        constraint_5a,\n",
    "        constraint_5b,\n",
    "        constraint_6a,\n",
    "        constraint_6b,\n",
    "    ]\n",
    "\n",
    "    if less_busy:\n",
    "        # Less busy: shade regions outside feasible set\n",
    "        for constraint in constraints:\n",
    "            ax.contourf(\n",
    "                xx,\n",
    "                yy,\n",
    "                constraint(xx, yy),\n",
    "                levels=[0, np.inf],\n",
    "                colors=[\"gray\"],\n",
    "                alpha=1,\n",
    "            )\n",
    "    else:\n",
    "        # Full plot: add detailed constraint lines\n",
    "        for constraint in constraints:\n",
    "            ax.contour(\n",
    "                xx,\n",
    "                yy,\n",
    "                constraint(xx, yy),\n",
    "                levels=[0],\n",
    "                colors=\"red\",\n",
    "                alpha=0.8,\n",
    "                linewidths=1.0,\n",
    "            )\n",
    "\n",
    "    # Mark points\n",
    "    x_min, y_min = res.x\n",
    "    ax.plot(x_min, y_min, \"mo\", label=\"Constrained Minimum\")\n",
    "    ax.plot(1, 1, \"yo\", label=\"Unconstrained Minimum\")\n",
    "\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.legend(loc=0, fontsize=\"small\")\n",
    "\n",
    "\n",
    "# Objective function and constraints\n",
    "def rosen(x):\n",
    "    return sum(100.0 * (x[1:] - x[:-1] ** 2.0) ** 2.0 + (1 - x[:-1]) ** 2.0)\n",
    "\n",
    "\n",
    "def cons_c(x):\n",
    "    return [x[0] ** 2 + x[1], x[0] ** 2 - x[1]]\n",
    "\n",
    "\n",
    "def cons_J(x):\n",
    "    return [[2 * x[0], 1], [2 * x[0], -1]]\n",
    "\n",
    "\n",
    "def cons_H(x, v):\n",
    "    return v[0] * np.array([[2, 0], [0, 0]]) + v[1] * np.array([[2, 0], [0, 0]])\n",
    "\n",
    "\n",
    "# Initialize constraint objects\n",
    "bounds = optimize.Bounds([0, -0.5], [1.0, 2.0])\n",
    "linear_constraint = optimize.LinearConstraint([[1, 2], [2, 1]], [-np.inf, 1], [1, 1])\n",
    "nonlinear_constraint = optimize.NonlinearConstraint(\n",
    "    cons_c, -np.inf, 1, jac=cons_J, hess=cons_H\n",
    ")\n",
    "\n",
    "# Solve the optimization\n",
    "x0 = np.array([0.5, 0])  # initial guess\n",
    "res = optimize.minimize(\n",
    "    rosen,\n",
    "    x0,\n",
    "    method=\"trust-constr\",\n",
    "    constraints=[linear_constraint, nonlinear_constraint],\n",
    "    bounds=bounds,\n",
    ")\n",
    "\n",
    "print(\"Result: \", res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rosen(less_busy=False);  # Full plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rosen(less_busy=True)  # Less busy plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "title": "Optimization",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
